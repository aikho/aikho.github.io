<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.3">Jekyll</generator><link href="https://aikho.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://aikho.github.io/" rel="alternate" type="text/html" /><updated>2018-09-04T01:27:40+03:00</updated><id>https://aikho.github.io/</id><title type="html">AIkho.github.io</title><subtitle>Блог о машинном обучении и разработке интеллектуальных систем</subtitle><author><name>Андрей Хобня</name></author><entry><title type="html">Ограничения машинного обучения в NLP/NLU</title><link href="https://aikho.github.io/2018/06/24/limitations-of-ml-for-nlp.html" rel="alternate" type="text/html" title="Ограничения машинного обучения в NLP/NLU" /><published>2018-06-24T21:00:00+03:00</published><updated>2018-06-24T21:00:00+03:00</updated><id>https://aikho.github.io/2018/06/24/limitations-of-ml-for-nlp</id><content type="html" xml:base="https://aikho.github.io/2018/06/24/limitations-of-ml-for-nlp.html">&lt;p&gt;Недавно Джастин Ли опубликовал статью “&lt;a href=&quot;https://blog.growthbot.org/chatbots-were-the-next-big-thing-what-happened&quot;&gt;Chatbots were the next big thing: what happened?&lt;/a&gt;”,
в которой он рассуждает о том, почему чат-боты до сих пор не заменили мобильные приложения, и чего ожидать от чат-ботов в будущем. Один из тезисов данной статьи:
NLP только начинает выходить за пределы исследовательских лабораторий и работает пока не достаточно хорошо. Поскольку сейчас в NLP используется в основном
машинное обучение, давайте попробуем разобраться более конкретно, насколько хорошо машинное обучение работает в NLP/NLU, и какие фундаментальные
ограничения существуют в этой области на данный момент.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://aikho.github.io/assets/img/2018-06-24-limitations-of-ml-for-nlp/chat-example.png&quot; alt=&quot;Чат-бот&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Рассмотрим современные модели классификации текста. Это могут быть, к примеру, сверточные нейронные сети или LSTM. Что они “выучивают” при машинном обучении?
Конечно, эти модели на самом деле не “понимают” смысла слов и предложений, как понимает их человек. Можно сказать, что нейронные сети “выучивают” паттерны,
которые статистически связаны с определенным классом. Поскольку сейчас повсеместно используются векторные представления слов, данные паттерны не являются
просто весами определенного слова или n-граммы в тексте, как это было при использовании более простых линейных моделей. Эти паттерны являются скорее паттернами
диапазонов координат слов и комбинаций слов в векторном пространстве. Это позволяет, например, распознавать паттерны даже при замене слов на близкие по смыслу.
Кроме того, некоторые модели, например LSTM, теоретически могут “выучивать” паттерны переменной длины. Все это, конечно, делает современные нейронные сети более
эффективными и “умными” для NLP по сравнению с используемыми ранее моделями или алгоритмами на основе ключевых слов. Однако, для создания моделей, полноценно
понимающих естественный язык, остается множество фундаментальных ограничений. Попробуем систематизировать эти ограничения.&lt;/p&gt;

&lt;h3 id=&quot;Контекст&quot;&gt;Контекст&lt;/h3&gt;

&lt;p&gt;Про проблему контекста говорят многие. Существуют различные подходы к решению данной проблемы при создании чат-ботов. Однако, в большинстве случаев проблему
контекста понимают слишком узко. Обычно под контекстом понимают информацию из предыдущих сообщений пользователя. Но понятие контекста гораздо шире.
Смысл одной и то же фразы может меняться в зависимости от того, кто, когда, каким тоном и при каких обстоятельствах данную фразу произнес. В таком широком
смысле чат-боты не понимают контекста сообщений пользователя. Можно попробовать подойти к решению данной проблемы различными способами. Например, передавать
данные о пользователе как фичи в модель, передавать предшествующее поведение пользователя на сайте или в приложении в модель и т.д. Однако, это достаточно
сложно и все равно не позволит в полной мере решить проблему контекста.&lt;/p&gt;

&lt;h3 id=&quot;concept-drift&quot;&gt;Concept Drift&lt;/h3&gt;

&lt;p&gt;Понятие &lt;a href=&quot;https://en.wikipedia.org/wiki/Concept_drift&quot;&gt;concept drift&lt;/a&gt; в машинном обучении означает, что статистические свойства данных могут меняться с течением
времени. Concept drift встречается в NLP-задачах. Язык постоянно изменяется, появляются новые слова, выражения и т.д.. Точность моделей машинного обучения
будет деградировать со временем. Существуют различные подходы к решению данной проблемы. Одним из способов является дообучение или переобучение моделей в
продакшене. Этот подход работает не всегда, т.к. характер распределения данных тоже может меняться со временем, а архитектура и гиперпараметры моделей могут
быть затюнены для текущих данных. Каким образом создавать чат-ботов, который будут подстраиваться под изменчивый сленг, пока до конца не ясно.&lt;/p&gt;

&lt;h3 id=&quot;reasoning&quot;&gt;Reasoning&lt;/h3&gt;

&lt;p&gt;Допустим чат-бот для бронирования билетов получит такое сообщение:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Забронируй столько билетов до Лондона, сколько пальцев на руке&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;С этой задачей справится любой живой человек. Даже ребенок знает сколько пальцев на руке. Но чат-бот будет, скорее всего, бессилен в решении данной простой
задачи (если только автор специально не предусмотрит конкретно эту ситуацию). Чат-боты на основе машинного обучения способны распознавать определенные сложные
паттерны в тексте, но они не способны провести простейшее рассуждение, вывести какой-либо результат из задачи и имеющихся фактов и затем использовать его в
дальнейшей работе. Да, существуют нейронные сети, которые отвечают на вопросы по картинке. Но, во-первых, данные модели весьма ограничены в своих возможностях.
Во-вторых, они все равно не осуществляют reasoning как таковой.&lt;/p&gt;

&lt;p&gt;Вообще, одним из популярных аргументов критиков машинного обучения из других областей AI является отсутствие ясного понимая того, как реализовать reasoning
при помощи машинного обучения. Хотя такие попытки делаются.&lt;/p&gt;

&lt;h3 id=&quot;Выводы&quot;&gt;Выводы&lt;/h3&gt;

&lt;p&gt;Современные нейронные сети являются более эффективными и “умными” моделями для NLP по сравнению с линейными моделями или алгоритмами на основе ключевых слов.
Однако, для создания систем, полноценно понимающих естественный язык, на данный момент существует множество фундаментальных ограничений.
Тем не менее, машинное обучение является отличным инструментом для решения многих практических задач в NLP/NLU.&lt;/p&gt;</content><author><name>Андрей Хобня</name></author><category term="ML" /><category term="NLP" /><category term="NLU" /><summary type="html">Недавно Джастин Ли опубликовал статью “Chatbots were the next big thing: what happened?”, в которой он рассуждает о том, почему чат-боты до сих пор не заменили мобильные приложения, и чего ожидать от чат-ботов в будущем. Один из тезисов данной статьи: NLP только начинает выходить за пределы исследовательских лабораторий и работает пока не достаточно хорошо. Поскольку сейчас в NLP используется в основном машинное обучение, давайте попробуем разобраться более конкретно, насколько хорошо машинное обучение работает в NLP/NLU, и какие фундаментальные ограничения существуют в этой области на данный момент.</summary></entry><entry><title type="html">Как работает AutoAugment?</title><link href="https://aikho.github.io/2018/06/05/how-does-autoaugment-work.html" rel="alternate" type="text/html" title="Как работает AutoAugment?" /><published>2018-06-05T21:00:00+03:00</published><updated>2018-06-05T21:00:00+03:00</updated><id>https://aikho.github.io/2018/06/05/how-does-autoaugment-work</id><content type="html" xml:base="https://aikho.github.io/2018/06/05/how-does-autoaugment-work.html">&lt;p&gt;На днях Google представил &lt;a href=&quot;https://ai.googleblog.com/2018/06/improving-deep-learning-performance.html&quot;&gt;AutoAugment&lt;/a&gt; – инструмент для оптимизации алгоритмов
аугментации наборов данных при помощи машинного обучения с подкреплением. Как AutoML, только не для архитектуры нейронной сети, а для алгоритмов аугментации. Хайп в соцсетях по
этому поводу не утихает. Но давайте разберемся, что именно сделали в Google и как это позволило улучшить результат распознавания объектов в CIFAR-10 на 0.65%.
В этом нам поможет публикация авторов AutoAugment.&lt;/p&gt;

&lt;p&gt;Итак, в научной статье про AutoAugment [&lt;a href=&quot;#r1&quot;&gt;1&lt;/a&gt;] в разделе 3 авторы пишут:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;We formulate the problem of finding the best augmentation policy as a discrete search problem.
In our search space, a policy consists of 5 sub-policies, each sub-policy consisting of two image
operations to be applied in sequence, each operation is also associated with two hyperparameters: 1)
the probability of applying the operation, and 2) the magnitude of the operation.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Т.е. авторы рассматривают задачу нахождения лучших методов аугментации как задачу дискретного поиска в некотором пространстве возможных методов.
Значит AutoAugment не может создать принципиально новый метод аугментации, а может лишь найти лучшую комбинацию из некоторого множества уже известных и
определенных методов. Причем количество операций в комбинации тоже заранее определено. Метод аугментации делится на 5 подметодов, каждый из которых
состоит из двух последовательных операций. Каждой операции соответствует два гиперпараметра: вероятностью применения и степень/величина применения.&lt;/p&gt;

&lt;p&gt;Из каких операций авторы формируют методы аугментации?&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;For generality, we considered all functions in PIL that accept an image as
input and output an image. We additionally used two other promising augmentation techniques:
Cutout [25] and SamplePairing [50]. The operations we searched over are ShearX/Y, TranslateX/Y,
Rotate, AutoContrast, Invert, Equalize, Solarize, Posterize, Contrast, Color, Brightness, Sharpness,
Cutout [25], Sample Pairing [50]. In total, we have 16 operations in our search space&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Из предыдущей цитаты нам известно, что используется 16 операций во всем пространстве поиска. Это не очень много. Например, библиотека imgaug поддерживает
около 50 трансформаций.&lt;/p&gt;

&lt;p&gt;Сам алгоритм AutoAugment похож на AutoML. Используется рекуррентная нейронная сеть, которая генерирует методы аугментации (5 подметодов по две операции с
гиперпараметрами). В качестве обратной связи для обучения с подкреплением используется точность дочерней нейронной сети (которая обучается распознавать
объекты при помощи аугментированного набора данных). Вот как описывают алгоритм сами авторы:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;The search algorithm has two components: a controller,
which is a recurrent neural network, and the training algorithm, which is the Proximal Policy Optimization
algorithm [52]. At each step, the controller predicts a decision produced by a softmax;
the prediction is then fed into the next step as an embedding. In total the controller has 30 softmax
predictions in order to predict 5 sub-policies, each with 2 operations, and each operation requiring an
operation type, magnitude and probability.
The controller is trained with a reward signal, which is how good the policy is in improving the
generalization of a “child model” (a neural network trained as part of the search process). In our
experiments, we set aside a validation set to measure the generalization of a child model. A child
model is trained with augmented data generated by applying the 5 sub-policies on the training set (that
does not contain the validation set). For each example in the mini-batch, one of the 5 sub-policies is
chosen randomly to augment the image. The child model is then evaluated on the validation set to
measure the accuracy, which is used as the reward signal to train the recurrent network controller&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Обратим внимание, что для измерения точности используется валидационный набор данных.&lt;/p&gt;

&lt;p&gt;Интуитивно, такая схема может работать лучше, чем ручной выбор методов аугментации, т.к. может более точно подобрать гиперпараметры трансформаций.
Также, обучение с подкреплением для этой задачи скорее всего работает эффективней, чем простой перебор. Хотя авторы публикации отмечают следующее:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;It might be possible to use a different discrete search algorithm such as genetic
programming [21] or even random search [24] to improve the results in this paper.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Интересное замечание.&lt;/p&gt;

&lt;h3 id=&quot;Выводы&quot;&gt;Выводы&lt;/h3&gt;

&lt;p&gt;AutoAugment – неплохой метод тюнинга методов аугментации наборов данных. AutoAugment не создает принципиально новые методы аугментации, а ищет лучшую
комбинацию из некоторого множества определенных трансформаций. Причем каждая такая комбинация состоит из 5 подкомбинаций по две трансформации.
Такой способ может работать лучше, чем ручной выбор методов аугментации, т.к. может более точно подобрать гиперпараметры трансформаций. Однако, AutoAugment не
отменяет вдумчивого применения методов аугментации для вашей задачи, а является лишь методом их тюнинга.
А что вы думаете про AutoAugment?&lt;/p&gt;

&lt;p&gt;Ссылки:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a name=&quot;r1&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://arxiv.org/abs/1805.09501&quot;&gt;AutoAugment: Learning Augmentation Policies from Data (arXiv:1805.09501)&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Андрей Хобня</name></author><category term="ML" /><category term="Метаобучение" /><summary type="html">На днях Google представил AutoAugment – инструмент для оптимизации алгоритмов аугментации наборов данных при помощи машинного обучения с подкреплением. Как AutoML, только не для архитектуры нейронной сети, а для алгоритмов аугментации. Хайп в соцсетях по этому поводу не утихает. Но давайте разберемся, что именно сделали в Google и как это позволило улучшить результат распознавания объектов в CIFAR-10 на 0.65%. В этом нам поможет публикация авторов AutoAugment.</summary></entry><entry><title type="html">Практический подход к задачам машинного обучения</title><link href="https://aikho.github.io/2018/05/30/practical-approach-to-ml-problems.html" rel="alternate" type="text/html" title="Практический подход к задачам машинного обучения" /><published>2018-05-30T23:45:00+03:00</published><updated>2018-05-30T23:45:00+03:00</updated><id>https://aikho.github.io/2018/05/30/practical-approach-to-ml-problems</id><content type="html" xml:base="https://aikho.github.io/2018/05/30/practical-approach-to-ml-problems.html">&lt;p&gt;Начинающие в области машинного обучения часто задают мне такой вопрос: “Мы уже изучили множество различных методов, моделей и подходов.
Допустим, приходит реальная задача. Как к ней подойти? Какие методы и как применять?”. В этой статье я попробую ответить на этот вопрос, описать практическую
методологию работы над задачей в области машинного обучения.&lt;/p&gt;

&lt;p&gt;Итак, есть задача, которая предполагает использование машинного обучения. Как к ней подступиться?&lt;/p&gt;

&lt;h3 id=&quot;1-Начните-с-решения-без-машинного-обучения&quot;&gt;1. Начните с решения без машинного обучения&lt;/h3&gt;

&lt;p&gt;Вам в любом случае понадобится базовая реализация для сравнения. Использовать машинное обучение имеет смысл только в тех случаях, когда оно работает лучше
других методов. Это очевидно! Но как узнать, что машинное обучение – лучший выбор в вашем случае? Начните с применения других методов, которые подходят
для вашей задачи.&lt;/p&gt;

&lt;p&gt;Ваша задача связана с классификацией текстов? Начните с использования ключевых слов. Используйте шаблоны. Используйте другие эвристики.
Существует множество NLP-инструментов, которые позволяют использовать правила и другие методы для решения таких задач.&lt;/p&gt;

&lt;p&gt;Ваша задача предполагает распознавание образов на изображениях? Используйте классические алгоритмы из OpenCV: детекторы контуров и контурный анализ,
распознавание по ключевым точкам (SIFT, детектор Хариса, HOG) и т.д.&lt;/p&gt;

&lt;p&gt;Распознавание событий во временных рядах? Начните с простых эвристик…&lt;/p&gt;

&lt;p&gt;Суть одна. Найдите классические алгоритмы/методы для решения похожих задач и начните с них решение вашей задачи. Возможно, применение простых эвристик уже
позволит решить вашу задачу на 99.9%. Останется ли тогда смысл инвестировать в более сложное решение на машинном обучении? А если классические методы будут
работать не очень хорошо или очень плохо для вашей задачи, тогда у вас появится отличный базис для сравнения эффективности ваших моделей машинного обучения.&lt;/p&gt;

&lt;p&gt;Часто при помощи машинного обучения улучшают уже существующие системы, которые работают на эвристиках и правилах. Если это ваш случай, изучите существующую
реализацию. Это даст вам лучшее понимание задачи и данных.&lt;/p&gt;

&lt;h3 id=&quot;2-Попробуйте-линейные-модели-машинного-обучения-и-деревья&quot;&gt;2. Попробуйте линейные модели машинного обучения и деревья&lt;/h3&gt;

&lt;p&gt;Если эвристики и правила не работают для вашей задачи (или работают не достаточно хорошо), переходите для начала к простым линейным моделям машинного обучения.&lt;/p&gt;

&lt;p&gt;Ваша задача связана с классификацией текстов? Попробуйте трансформировать тексты в Bag-of-Words и применить логистическую регрессию или SVM.
Bag-of-Words работает плохо для вашей задачи? Используйте TF-IDF.&lt;/p&gt;

&lt;p&gt;У вас задача по распознаванию образов на изображениях? Используйте детекторы признаков и логистическую регрессию или SVM.&lt;/p&gt;

&lt;p&gt;Предиктивная модель продаж? Используйте линейную регрессию.&lt;/p&gt;

&lt;p&gt;Теггинг слов в последовательности? Попробуйте CRF…&lt;/p&gt;

&lt;p&gt;Попробуйте простую линейную модель. Возможно при помощии нее вы уже решите задачу. Линейная модель работает плохо? Проанализируйте, какие ошибки совершает
ваша модель. Возможно ее можно улучшить, спроектировав лучшие признаки.&lt;/p&gt;

&lt;p&gt;У вас текстовые данные? Попробуйте в качестве признаков n-граммы, суффиксы, регулярные выражения, знаки препинания и т.д. У вас табличные данные?
Попробуйте различные комбинации признаков, степени, логарифмы и т.д. (которые имеют смысл для ваших данных).&lt;/p&gt;

&lt;p&gt;Также, если у вас табличные данные, попробуйте модели на основе деревьев. Деревья решений, случайные леса, градиентный бустинг.&lt;/p&gt;

&lt;p&gt;Линейные модели и деревья не дают необходимого результата, а проектирование признаков не выглядит реалистичным занятием? Тогда переходите к глубоким нейронным сетям.&lt;/p&gt;

&lt;h3 id=&quot;3-Попробуйте-стандартные-модели-глубоких-нейронных-сетей&quot;&gt;3. Попробуйте стандартные модели глубоких нейронных сетей&lt;/h3&gt;

&lt;p&gt;Классификация объектов на изображениях? Начните с тюнинга на своих данных стандартных моделей глубоких нейронных сетей (VGG, Inception, ResNet и т.д.),
обученных на ImageNet.&lt;/p&gt;

&lt;p&gt;Классификация текстов? Используйте обученные векторные представления слов и сверточную нейронную сеть поверх.&lt;/p&gt;

&lt;p&gt;Теггинг слов? Используйте векторные представления слов и рекуррентную нейронную сеть.&lt;/p&gt;

&lt;p&gt;Возьмите стандартную известную архитектуру нейронной сети и примените ее для своей задачи самым общепринятым способом. Скорее всего, для вашей задачи
она не будет работать так же хорошо, как для изначального набора данных, для которого она проектировалась. Однако, это будет отправной точкой вашего решения.&lt;/p&gt;

&lt;h3 id=&quot;4-Проанализируйте-вашу-модель&quot;&gt;4. Проанализируйте вашу модель&lt;/h3&gt;

&lt;p&gt;Проанализируйте метрики модели на тренировочных и валидационных данных. Ваша модель недообучается или переобучается?&lt;/p&gt;

&lt;p&gt;Проанализируйте как шел процесс обучения модели. Как выглядят кривые изменения значения функции ошибки?&lt;/p&gt;

&lt;p&gt;Сделайте рандомизированную выборку данных, для которых модель работает не верно. Например, сто примеров, в которых модель не правильно распознает объекты
на изображениях или не правильно классифицирует тексты. Изучите данную выборку, выделите типовые случаи, в которых модель ошибается. Например, ваша нейронная
сеть ошибается, когда объект на изображении очень маленький, или при определенном фоне, или когда размыта какая-то часть объекта, или когда в тексте
встречаются определенные слова, или когда тексты очень длинные и т.д. Определите, какие признаки повлияли на неверное решение модели. Для этого можно использовать
различные инструменты.&lt;/p&gt;

&lt;p&gt;Переходите к следующему разделу.&lt;/p&gt;

&lt;h3 id=&quot;5-Улучшите-вашу-модель&quot;&gt;5. Улучшите вашу модель&lt;/h3&gt;

&lt;p&gt;На основе анализа из предыдущего раздела и ваших возможностей примите решение, какие методы улучшения точности модели рационально использовать,
и попробуйте применить данные методы. Приведу основные типы доступных методов:&lt;/p&gt;

&lt;h4 id=&quot;1-Используйте-больше-данных&quot;&gt;1) Используйте больше данных&lt;/h4&gt;

&lt;p&gt;Если у вас есть такая возможность, используйте ее. Глубокие нейронные сети работают очень хорошо на больших объемах данных.
Большее количество данных может работать как регуляризация модели. Если ваша нейронная сеть хорошо выучивает тренировочные данные, попробуйте добавить больше,
это может сработать.&lt;/p&gt;

&lt;h4 id=&quot;2-Сгенерируйте-больше-данных&quot;&gt;2) Сгенерируйте больше данных&lt;/h4&gt;

&lt;p&gt;Расширьте свой набор данных синтетическими данными. Это особенно хорошо работает для изображений. Используйте случайные трансформации и сдвиги. Подумайте,
какие трансформации имеют реальный смысл для ваших данных. Этот метод можно применять и для табличных данных. Можно использовать генеративные модели для
создания синтетических данных. Расширение набора данных – популярная техника.&lt;/p&gt;

&lt;h4 id=&quot;3-Используйте-спроектированные-признаки&quot;&gt;3) Используйте спроектированные признаки&lt;/h4&gt;

&lt;p&gt;Если вы используете глубокое обучение, это не значит, что вы обязаны использовать исключительно сырые данные. Если существует понятный признак, который легко
определить простым алгоритмом, и наличие которого коррелирует с результатом, то почему бы этим не воспользоваться? Особенно, если ваша модель часто ошибается
на тех примерах, где этот признак присутствует и может быть использован.&lt;/p&gt;

&lt;h4 id=&quot;4-Используйте-transfer-learning&quot;&gt;4) Используйте Transfer Learning&lt;/h4&gt;

&lt;p&gt;Вы не можете достать больше данных для своей задачи? Примените творческий подход. Найдите близкую задачу, для которой доступно огромное количество данных.
Обучите вашу нейронную сеть этой задаче на этом огромном количестве данных. Затем используйте часть обученной модели в качестве детекторов признаков для
вашей задачи. Или используйте тюнинг обученной модели для вашей задачи.&lt;/p&gt;

&lt;h4 id=&quot;5-Используйте-multitask-learning&quot;&gt;5) Используйте Multitask Learning&lt;/h4&gt;

&lt;p&gt;Обучите вашу нейронную сети выполнять дополнительные задачи, кроме исходной. Например, распознавать дополнительные свойства. Это может сработать как
регуляризация модели.&lt;/p&gt;

&lt;h4 id=&quot;6-Разбейте-задачу-на-подзадачи&quot;&gt;6) Разбейте задачу на подзадачи&lt;/h4&gt;

&lt;p&gt;Возможно ваша задача слишком сложна для создания end-to-end learning модели. Разбейте ее на подзадачи, обучите модель машинного обучения для каждой подзадачи.
Объедините модели машинного обучения в систему. Очевидно, что разбивать задачу на подзадачи необходимо таким образом, чтобы для подзадач существовали данные
для машинного обучения.&lt;/p&gt;

&lt;h4 id=&quot;7-Используйте-методы-регуляризации&quot;&gt;7) Используйте методы регуляризации&lt;/h4&gt;

&lt;p&gt;Попробуйте L1- и L2-регуляризации и дропаут. Если ваша модель сильно переобучается и вы получаете огромные веса, эти простые техники могут сработать.&lt;/p&gt;

&lt;h4 id=&quot;8-Используйте-больше-нейроновфильтров&quot;&gt;8) Используйте больше нейронов/фильтров&lt;/h4&gt;

&lt;p&gt;Если ваша модель недообучается, попробуйте увеличить емкость модели, добавляя больше нейронов/фильтров.&lt;/p&gt;

&lt;h4 id=&quot;9-Используйте-больше-слоев&quot;&gt;9) Используйте больше слоев&lt;/h4&gt;

&lt;p&gt;Добавление нейронов увеличивает емкость сети, но приводит к худшей генерализации? Попробуйте использовать больше слоев.&lt;/p&gt;

&lt;h4 id=&quot;10-Используйте-residual-соединения&quot;&gt;10) Используйте Residual-соединения&lt;/h4&gt;

&lt;p&gt;Добавление большего количества слоев становится проблематичным? Используйте Residual-соединения.&lt;/p&gt;

&lt;h4 id=&quot;11-Оптимизируйте-архитектуру-нейронной-сети&quot;&gt;11) Оптимизируйте архитектуру нейронной сети&lt;/h4&gt;

&lt;p&gt;Подберите оптимальные размеры слоев, количества фильтров, типы нейронов, функции активации и т.д. Создать архитектуру нейронную сети, оптимальную для
конкретной задачи, достаточно сложно, требует глубокого анализа обученных моделей, исcледования данных и множества экспериментов. Оптимально спроектированная
архитектура может обучаться гораздо лучше, чем стандартная.&lt;/p&gt;

&lt;h4 id=&quot;12-Оптимизируйте-параметры-алгоритма-оптимизации&quot;&gt;12) Оптимизируйте параметры алгоритма оптимизации&lt;/h4&gt;

&lt;p&gt;Значение функции ошибки достигает плато? Обучение сходится в локальном минимуме? Используйте момент, момент Нестерова, адаптивные версии градиентного спуска
и т.д. Оптимизируйте параметры алгоритма оптимизации.&lt;/p&gt;

&lt;h4 id=&quot;13-Используйте-ансамбли-моделей&quot;&gt;13) Используйте ансамбли моделей&lt;/h4&gt;

&lt;p&gt;Не получается создать одну универсальную модель? Разные версии модели делают различные типы ошибок? Используйте ансамбли моделей. Обучите несколько моделей.
Используйте их результаты как входные данные для линейной модели машинного обучения или просто вычисляйте среднее.&lt;/p&gt;

&lt;h4 id=&quot;14-Используйте-экспериментальные-методы&quot;&gt;14) Используйте экспериментальные методы&lt;/h4&gt;

&lt;p&gt;Если вы исчерпали почти все подходы, но у вас есть огромные ресурсы, вы можете начать исследовать новые типы нейронов и слоев, исследовать что-то
принципиально новое и написать об этом научную статью :)&lt;/p&gt;

&lt;p&gt;У меня получился не исчерпывающий и упрощенный список. Но, я думаю, основные направления понятны. После улучшения модели, переходите обратно к разделу 4.
Улучшение модели – это итеративный процесс.&lt;/p&gt;

&lt;h3 id=&quot;Заключение&quot;&gt;Заключение&lt;/h3&gt;

&lt;p&gt;Надеюсь, что мне удалось ответить на вопрос “как подойти к задаче в области машинного обучения?” и объяснить как происходит последовательная работа над
решением. А что вы думаете по этому вопросу?&lt;/p&gt;</content><author><name>Андрей Хобня</name></author><category term="ML" /><category term="Tutorial" /><category term="Overview" /><summary type="html">Начинающие в области машинного обучения часто задают мне такой вопрос: “Мы уже изучили множество различных методов, моделей и подходов. Допустим, приходит реальная задача. Как к ней подойти? Какие методы и как применять?”. В этой статье я попробую ответить на этот вопрос, описать практическую методологию работы над задачей в области машинного обучения.</summary></entry><entry><title type="html">Архитектура чат-ботов с обработкой естественного языка</title><link href="https://aikho.github.io/2018/05/11/architecture-of-task-oriented-chat-bots.html" rel="alternate" type="text/html" title="Архитектура чат-ботов с обработкой естественного языка" /><published>2018-05-11T23:10:00+03:00</published><updated>2018-05-11T23:10:00+03:00</updated><id>https://aikho.github.io/2018/05/11/architecture-of-task-oriented-chat-bots</id><content type="html" xml:base="https://aikho.github.io/2018/05/11/architecture-of-task-oriented-chat-bots.html">&lt;p&gt;В данной статье я попробую систематизировать современные подходы и собственный опыт построения чат-ботов, ориентированных на выполнение специализированных задач,
формулируемых пользователями на естественном языке. Как правило, такие чат-боты представляют собой гибридные системы, объединяющие модели машинного обучения,
классические алгоритмы и движки правил. Как они устроены?&lt;/p&gt;

&lt;p&gt;Если обобщить находящуюся в публичном доступе информацию [&lt;a href=&quot;#r1&quot;&gt;1&lt;/a&gt;, &lt;a href=&quot;#r2&quot;&gt;2&lt;/a&gt;, &lt;a href=&quot;#r3&quot;&gt;3&lt;/a&gt;, …] и собственный опыт проектирования чат-ботов, структуру бота можно примерно изобразить следующим образом:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://aikho.github.io/assets/img/2018-05-10-architecture-of-task-oriented-chat-bots/ChatBotDiagram.png&quot; alt=&quot;Архитектура чат-бота&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Разберем устройство каждого блока. Итак, сначала текст пользователя преобразуется в последовательность &lt;strong&gt;токенов&lt;/strong&gt; при помощи токенизатора (&lt;strong&gt;tokenizer&lt;/strong&gt;).
Как правило, токенизаторы разбивают текст на отдельные слова.&lt;/p&gt;

&lt;p&gt;Допустим, мы создаем бота, который позволяет искать информацию о фьючерсах и курсах валют.
Пользователь пишет сообщение: “Найди мне цены нефтяных фьючерсов WTI на январь!!!”. Токинизатор разделит данную фразу следующим образом:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://aikho.github.io/assets/img/2018-05-10-architecture-of-task-oriented-chat-bots/text1.png&quot; alt=&quot;Токенизация текста&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Далее последовательность токенов передается в компонент &lt;strong&gt;распознавания сущностей&lt;/strong&gt; (&lt;strong&gt;entity recognizer&lt;/strong&gt;), который распознает отдельные токены или N-граммы токенов как &lt;strong&gt;сущности&lt;/strong&gt; (&lt;strong&gt;entity&lt;/strong&gt;).
Типы распознаваемых сущностей зависят от задач, которые выполняет чат-бот. Это могут быть имена, названия, коды, обозначения валют, серийные номера и т.д.
Для распознавания сущностей используются, как правило, классические алгоритмы: поиск по словарям, регулярные выражения, ключевые слова и т.д.
Компонент распознавания сущностей генерирует последовательность тегов, которые маркируют токены.
Зачем предварительно распознавать сущности при помощи обычного поиска, если мы собираемся применить машинное обучение? На это есть несколько причин:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;в обучающем наборе данных могут быть представлены не все возможные сущности;&lt;/li&gt;
  &lt;li&gt;создание датасета со всеми возможными комбинациями сущностей может быть непрактичным;&lt;/li&gt;
  &lt;li&gt;данный подход позволяет добавлять новые сущности без переобучения моделей.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;В примере выше название марки нефти WTI является сущностью, которую чат-бот мог бы распознать, используя таблицу наименований фьючерсов.
Исходная последовательность токенов была бы промаркирована следующей последовательностью тегов:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://aikho.github.io/assets/img/2018-05-10-architecture-of-task-oriented-chat-bots/text2.png&quot; alt=&quot;Распознавание сущностей&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Где &lt;strong&gt;0&lt;/strong&gt; – токен не относится к сущности, &lt;strong&gt;name&lt;/strong&gt; – токен относится к названию фьючерса.&lt;/p&gt;

&lt;p&gt;Затем последовательность токенов и тегов передается в &lt;strong&gt;векторизатор&lt;/strong&gt; (&lt;strong&gt;vectorizer&lt;/strong&gt;). Векторизатор преобразует отдельные слова в числовые последовательности (векторные представления).
Для этого могут использоваться модели Word2Vec, GLOVE или FastText, предобученные на больших корпусах текстов. Однако, если задачи бота узкоспециализированные, и
имеется большой набор данных для обучения, то могут использоваться и самостоятельно обученные модели.
Перед преобразованием в вектора обычно осуществляется простейший препроцессинг: удаляются стоп-слова, используется стемминг и т.д.
После преобразования к векторам добавляются признаки тегов сущностей.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://aikho.github.io/assets/img/2018-05-10-architecture-of-task-oriented-chat-bots/text3.png&quot; alt=&quot;Векторные представления&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Затем последовательность векторов передается в компонент &lt;strong&gt;понимания естественного языка&lt;/strong&gt; (&lt;strong&gt;natural language understanding – NLU&lt;/strong&gt;) и комбинируется с
текущим состоянием диалога (если до этого пользователь писал какие-либо сообщения, то текущая фраза уже должна рассматриваться в контексте) [&lt;a href=&quot;#r4&quot;&gt;4&lt;/a&gt;].
NLU выполняет две подзадачи:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;идентификация задачи, которую хочет выполнить пользователь (&lt;strong&gt;intent classification&lt;/strong&gt;);&lt;/li&gt;
  &lt;li&gt;выделение параметров задачи из сообщения пользователя (&lt;strong&gt;slot tagging&lt;/strong&gt;).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Первая задача является задачей классификации. Вторая – задачей преобразования последовательности (seq2seq). Как правило, данные подзадачи решаются при помощи
моделей машинного обучения. Может использоваться одна комбинированная нейронная сеть для решения двух задач одновременно, либо отдельная нейросеть для
классификации задач и свой slot tagger для каждой задачи. Единственного универсального варианта реализации NLU не существует.
Если задача определяется в большинстве случаев комбинацией представленных слотов (например, необходимо различать несколько видов поиска по различным параметрам),
то с большей долей вероятности комбинированная модель покажет лучший результат. Если класс задачи в меньшей степени зависит от слотов, то стоит рассмотреть вариант с
отдельными моделями.&lt;/p&gt;

&lt;p&gt;Также существует множество вариантов архитектур моделей, котрые можно использовать для классификации и теггинга. Можно использовать двунаправленный LSTM, GRU, CNN, СNN с Gated Linear Unit [&lt;a href=&quot;#r5&quot;&gt;5&lt;/a&gt;],
Q-RNN [&lt;a href=&quot;#r6&quot;&gt;6&lt;/a&gt;] и т.д. Помните, no free lunch [&lt;a href=&quot;#r7&quot;&gt;7&lt;/a&gt;]!&lt;/p&gt;

&lt;p&gt;Допустим, фраза из нашего примера должна запускать задачу findPriceByNameAndMonth. Эта задача имеет два слота: name и month.
Допустим, классификатор и теггер слотов корректно определили данную задачу и слоты:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://aikho.github.io/assets/img/2018-05-10-architecture-of-task-oriented-chat-bots/text4.png&quot; alt=&quot;Классификация и теггинг слотов&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Теперь класс задачи и значения слотов передаются в &lt;strong&gt;менеджер диалогов&lt;/strong&gt; (&lt;strong&gt;dialog manager&lt;/strong&gt;). Менеджер диалогов запускает задачи, вызывая API &lt;strong&gt;внешних систем&lt;/strong&gt;, обновляет текущее &lt;strong&gt;состояние&lt;/strong&gt;
(&lt;strong&gt;state&lt;/strong&gt;) и управляет ведением диалога с пользователем. Политика ведения диалога может быть реализована при помощи жестко описанного алгоритма, движка правил или модели машинного
обучения. Зачем такие сложности? В приведенном выше примере все действительно просто: в одной фразе пользователя содержится указание на задачу и значения всех слотов для нее.
Но что, если пользователь не укажет информацию для всех необходимых слотов? Тогда необходимо добавить чат-боту способность задавать уточняющие вопросы. Но что, если затруднительно точно
определить, какую задачу имел в виду пользователь, и существует несколько вариантов того, какие именно слоты были пропущены? Поведение менеджера диалогов в данном случае может определятся
моделью машинного обучения, а может программироваться при помощи правил.&lt;/p&gt;

&lt;p&gt;Для того, чтобы сохранять контекст и информацию из предыдущих сообщений пользователя, менеджер диалогов обновляет
состояние. Это состояние используется в NLU для того, чтобы учитывать контекст при классификации задач и теггинге слотов. Управление состоянием – достаточно сложная составляющая менеджера
диалогов. Например, необходимо учитывать, что пользователь может “передумать” и потребовать выполнить другую задачу. Или потребовать выполнить другую задачу, но со слотами из предыдущей
задачи.&lt;/p&gt;

&lt;p&gt;Также менеджер диалогов отвечает за генерацию ответов пользователя. Для этого могут использоваться простые шаблоны, а могут и генеративные модели.&lt;/p&gt;

&lt;h3 id=&quot;Заключение&quot;&gt;Заключение&lt;/h3&gt;

&lt;p&gt;Чат-боты с обработкой естественного языка, ориентированные на выполнение определенных задач, представляют собой достаточно сложные гибридные системы, объединяющие модели машинного обучения,
классические алгоритмы и движки правил. В данной статье рассмотрен общий подход к построению подобных систем, не касаясь деталей реализации, обучения нейронных сетей,
обеспечения масштабируемости, интеграции с внешними системами и т.д.&lt;/p&gt;

&lt;p&gt;Даже рассматривая архитектуру чат-ботов с NLP на высоком уровне, можно сделать вывод, что разработка
собственного специализированного чат-бота может потребовать исследования и решения достаточно сложных задач. Это зависит во многом от того, насколько сложны и специализированы
задания, выполняемые ботом, и как они формулируются пользователями.&lt;/p&gt;

&lt;p&gt;Ссылки:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a name=&quot;r1&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://www.youtube.com/watch?v=cPeKV46Xb_g&quot;&gt;Spoken Dialog Systems – Task Oriented Systems&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;r2&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://habr.com/company/yandex/blog/349372/&quot;&gt;Как устроена Алиса. Лекция Яндекса&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;r3&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://www.codeproject.com/Articles/51026/True-Natural-Language-Understanding-through-a-Conc&quot;&gt;True Natural Language Understanding through a Conceptual Language Understanding Engine&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;r4&quot;&gt;&lt;/a&gt; &lt;a href=&quot;http://www.cs.toronto.edu/~aditya/publications/contextual.pdf&quot;&gt;Easy contextual intent prediction and slot detection&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;r5&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://arxiv.org/abs/1612.08083v2&quot;&gt;Language Modeling with Gated Convolutional Networks (arXiv:1612.08083)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;r6&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://arxiv.org/abs/1611.01576&quot;&gt;Quasi-Recurrent Neural Networks (arXiv:1611.01576)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;r7&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://en.wikipedia.org/wiki/No_free_lunch_theorem&quot;&gt;No free lunch theorem&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Андрей Хобня</name></author><category term="ML" /><category term="NLP" /><category term="NLU" /><category term="Архитектура" /><summary type="html">В данной статье я попробую систематизировать современные подходы и собственный опыт построения чат-ботов, ориентированных на выполнение специализированных задач, формулируемых пользователями на естественном языке. Как правило, такие чат-боты представляют собой гибридные системы, объединяющие модели машинного обучения, классические алгоритмы и движки правил. Как они устроены?</summary></entry><entry><title type="html">Что автоматизирует AutoML?</title><link href="https://aikho.github.io/2018/05/01/what-does-automl-automate.html" rel="alternate" type="text/html" title="Что автоматизирует AutoML?" /><published>2018-05-01T18:20:00+03:00</published><updated>2018-05-01T18:20:00+03:00</updated><id>https://aikho.github.io/2018/05/01/what-does-automl-automate</id><content type="html" xml:base="https://aikho.github.io/2018/05/01/what-does-automl-automate.html">&lt;p&gt;В мае 2017 года исследователи из Google Brain team представили &lt;a href=&quot;https://research.googleblog.com/2017/05/using-machine-learning-to-explore.html&quot;&gt;AutoML&lt;/a&gt; – алгоритм,
который позволяет автоматически создавать архитектуры нейронных сетей, используя обучение с подкреплением. Через несколько месяцев они успешно применили AutoML
для создания нейросети &lt;a href=&quot;https://research.googleblog.com/2017/11/automl-for-large-scale-image.html&quot;&gt;NASNet&lt;/a&gt;. Многие высказывали мнение, что теперь создавать
нейронные сети сможет каждый и не нужны будут специалисты в этой области. Однако, на данный момент создавать новые модели машинного обучения все так же сложно.
Так что же сделали в Google Brain team? В этом нам помогут разобраться публикации авторов AutoML.&lt;/p&gt;

&lt;p&gt;Сразу следует отметить, что сама идея метаобучения (обучения алгоритмов и моделей обучения, meta learning [&lt;a href=&quot;#r1&quot;&gt;1&lt;/a&gt;])
не нова. Работы в данной области публикуют примерно с 1991 года. Обучение с подкреплением не единственный метод метаобучения. Рассматриваются также генетические
алгоритмы и другие подходы. Но давайте перейдем непосредственно к научной статье авторов AutoML [&lt;a href=&quot;#r2&quot;&gt;2&lt;/a&gt;].&lt;/p&gt;

&lt;p&gt;В разделе “3 Methods”, а именно в “3.1 Generate model descriptions with a controller recurrent neural network” авторы пишут:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;In Neural Architecture Search, we use a controller to generate architectural hyperparameters of
neural networks. To be flexible, the controller is implemented as a recurrent neural network.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Авторы обучают рекуррентную нейронную сеть, называемую контроллером, выводить гиперпараметры искомой архитектуры нейронной сети.&lt;/p&gt;

&lt;p&gt;Далее в данном разделе приводится пример предсказания архитектуры нейронной сети, состоящей из одних сверточных слоев. В данном примере, рекуррентная сеть выводит последовательно
5 гиперпараметров для каждого слоя: высота фильтра, ширина фильтра, высота шага, ширина шага и количество фильтров.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Once the controller RNN finishes generating an architecture, a neural network with this architecture is built
and trained. At convergence, the accuracy of the network on a held-out validation set is recorded.
The parameters of the controller RNN, θc, are then optimized in order to maximize the expected
validation accuracy of the proposed architectures. In the next section, we will describe a policy
gradient method which we use to update parameters θc so that the controller RNN generates better
architectures over time.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;После того как контроллер сгенерировал гиперпараметры, строится архитектура новой нейронной сети, затем созданная сеть обучается, вычисляется ее точность.
Затем на основе данной обратной связи происходит обучение нейронной сети контроллера. Таким образом, контроллер обучается генерировать лучшие гиперпараметры архитектуры
при помощи обучения с подкреплением.&lt;/p&gt;

&lt;p&gt;Т.е. &lt;strong&gt;AutoML не генерирует произвольные архитектуры&lt;/strong&gt;. Чтобы использовать AutoML для своей задачи, необходимо определить нечто вроде &lt;em&gt;метаархитектуры&lt;/em&gt; нейронной сети:
типы слоев, соединений, изменяемые гиперпараметры и т.д.&lt;/p&gt;

&lt;p&gt;Но если AutoML не генерирует произвольные архитектуры, каким образом тогда она сгенерировала новый тип рекуррентных слоев? Посмотрим, что пишут об этом авторы в разделе 3.4:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The computations for basic RNN and LSTM cells can be generalized as a tree of steps that take xt
and ht−1 as inputs and produce ht as final output. The controller RNN needs to label each node in
the tree with a combination method (addition, elementwise multiplication, etc.) and an activation
function (tanh, sigmoid, etc.) to merge two inputs and produce one output. Two outputs are then
fed as inputs to the next node in the tree. To allow the controller RNN to select these methods and
functions, we index the nodes in the tree in an order so that the controller RNN can visit each node
one by one and label the needed hyperparameters.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Авторы представили рекуррентную ячейку как дерево с тремя узлами. Каждому узлу соответствует функция комбинации и функция активации.
Функции выбираются из списка. Нейронная сеть контроллера учится выбирать функции, которые дадут лучший результат.&lt;/p&gt;

&lt;p&gt;Хорошо, но каким образом удалось применить AutoML для создания NASNet, ведь архитектура NASNet достаточно сложна?
Изучим соответствующую работу [&lt;a href=&quot;#r3&quot;&gt;3&lt;/a&gt;]. В разделе “3. Method” авторы пишут:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;In our approach, the overall architectures of the convolutional
nets are manually predetermined. They are composed
of convolutional cells repeated many times where
each convolutional cell has the same architecture, but different
weights.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Архитектуры сверточных сетей предопределены вручную. Они состоят из сверточных блоков, которые повторяются множество раз и имеют одинаковую архитектуру,
но различные веса. Это похоже на идею архитектуры Inception, которая тоже состоит из повторяющихся блоков.&lt;/p&gt;

&lt;p&gt;В этом же разделе авторы пишут:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The main contribution of this work is the design of a
novel search space, such that the best architecture found
on the CIFAR-10 dataset would scale to larger, higher-resolution
image datasets across a range of computational
settings.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Т.е. авторы тренируют AutoML на датасете CIFAR-10. Получают оптимальную архитектуру сверточного блока. Затем из полученных одинаковых блоков строят нейронную сеть
для датасета изображений с более высоким разрешением, т.е. ImageNet. Основной принцип сохраняется – сначала определяется метаархитектура и ее гиперпараметры,
затем осуществляется поиск оптимальных значений гиперпараметров при помощи машинного обучения с подкреплением.&lt;/p&gt;

&lt;p&gt;Зачем оптимизировать архитектуру блока на CIFAR-10, а потом пытаться ее масштабировать на ImageNet? Почему бы не применить AutoML непосредственно к ImageNet?
Чтобы в этом разобраться, обратим внимание на данные из раздела “4. Experiments and Results”:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The method in this paper
uses 500 GPUs across 4 days resulting in 2,000 GPU-hours. The former
effort used Nvidia K40 GPUs, whereas the current efforts used faster
NVidia P100s.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Карта NVidia P100s сейчас стоит примерно &lt;a href=&quot;https://www.amazon.com/gp/offer-listing/B06WV7HFWV/?ie=UTF8&amp;amp;condition=new&quot;&gt;6’500$&lt;/a&gt;.
Авторы использовали 500 штук. Получается, чтобы обучить AutoML за 4 дня даже на таком “игрушечном” датасете как CIFAR-10, необходимо
иметь доступ к оборудованию на 3’250’000$? На данный момент это так. А чтобы обучать AutoML на ImageNet, необходимо ресурсов
минимум на пару порядков больше.&lt;/p&gt;

&lt;h3 id=&quot;Выводы&quot;&gt;Выводы&lt;/h3&gt;

&lt;p&gt;AutoML – неплохой метод тюнинга архитектуры моделей машинного обучения. Однако, он не способен решить вашу задачу автоматически.
Для того, чтобы использовать AutoML для новой задачи, необходимо задать метаархитектуру модели (нейронной сети): типы слоев, соединений,
изменяемые гиперпараметры и т.д. Кроме того, применение AutoML требует использования большого количества вычислительных ресурсов.&lt;/p&gt;

&lt;p&gt;Ссылки:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a name=&quot;r1&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://en.wikipedia.org/wiki/Meta_learning_(computer_science)&quot;&gt;Meta Learning&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;r2&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://arxiv.org/abs/1611.01578&quot;&gt;Neural Architecture Search with Reinforcement Learning (arXiv:1611.01578)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;r3&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://arxiv.org/abs/1707.07012&quot;&gt;Learning Transferable Architectures for Scalable Image Recognition (arXiv:1707.07012)&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Андрей Хобня</name></author><category term="ML" /><category term="Метаобучение" /><summary type="html">В мае 2017 года исследователи из Google Brain team представили AutoML – алгоритм, который позволяет автоматически создавать архитектуры нейронных сетей, используя обучение с подкреплением. Через несколько месяцев они успешно применили AutoML для создания нейросети NASNet. Многие высказывали мнение, что теперь создавать нейронные сети сможет каждый и не нужны будут специалисты в этой области. Однако, на данный момент создавать новые модели машинного обучения все так же сложно. Так что же сделали в Google Brain team? В этом нам помогут разобраться публикации авторов AutoML.</summary></entry><entry><title type="html">Увеличение скорости машинного обучения</title><link href="https://aikho.github.io/2018/04/24/machine-learning-training-performance.html" rel="alternate" type="text/html" title="Увеличение скорости машинного обучения" /><published>2018-04-24T23:10:00+03:00</published><updated>2018-04-24T23:10:00+03:00</updated><id>https://aikho.github.io/2018/04/24/machine-learning-training-performance</id><content type="html" xml:base="https://aikho.github.io/2018/04/24/machine-learning-training-performance.html">&lt;p&gt;Большинство последних улучшений и прорывов в машинном обучении происходило в основном в области создания моделей, которые обучаются лучше, чем их предшественники.
При этом, чем точнее модель, тем, как правило, выше ее вычислительная сложность.
Конечно, доступные вычислительные мощности растут, железо совершенствуется, развиваются оптимизированные под глубокое обучение библиотеки. Тем не менее,
работа с наиболее передовыми моделями машинного обучения требует все большего количества ресурсов. Поэтому нам нужны не только более точные модели,
но и более эффективные алгоритмы обучения.
Какие исследования в данном направлении сейчас ведутся и что уже сделано?&lt;/p&gt;

&lt;p&gt;Для удобства и систематизации я условно разделяю все способы ускорения обучения на три большие группы:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Улучшение алгоритмов оптимизации&lt;/strong&gt;. К этой группе способов относится применение адаптивных алгоритмов обучения, различных вариаций стохастического градиентного спуска,
применение различных вариантов динамического изменения параметров оптимизатора и т.д.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Улучшение самих моделей машинного обучения&lt;/strong&gt;. Некоторые модели обучаются не только лучше, но и быстрее других моделей.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Оптимизация &lt;em&gt;применения&lt;/em&gt; алгоритмов оптимизации&lt;/strong&gt;. Сюда относятся различные вариации применения алгоритмов оптимизации к модели: последовательное обучение различных частей модели,
применение нескольких алгоритмов оптимизации, инициализация параметров модели до применения оптимизации и т.д.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Рассмотрим работы в каждом из направлений.&lt;/p&gt;

&lt;h3 id=&quot;Улучшение-алгоритмов-оптимизации&quot;&gt;Улучшение алгоритмов оптимизации&lt;/h3&gt;

&lt;p&gt;Исследования 2016-2018 годов в данной области рассматривают в основном способы улучшения алгоритма стохастического градиентного спуска и адаптивных алгоритмов.&lt;/p&gt;

&lt;p&gt;Например, предложен метод нормализованного градиента с адаптивным размером шага [&lt;a href=&quot;#r1&quot;&gt;1&lt;/a&gt;]. Метод включает в себя применение двух последовательных шагов: вычисление и нормализация градиента
и выбор адаптивного шага для обновления параметров. Этот метод может применятся к алгоритму стохастического градиентного спуска, алгоритму ADAM, AdaGrad и другим.
Авторы провели несколько экспериментов, включая обучение перцептрона, сверточной и рекурентной нейронной сети, и выяснили, что данный метод может значительно ускорять
оптимизацию глубоких нейронных сетей от 18 слоев или рекурентных сетей развернутых от 40 до 1000 шагов.&lt;/p&gt;

&lt;p&gt;Предложен алгоритм неустойчивого стохастического градиентного спуска (Inconsistent Stochastic Gradient Descent – ISGD) [&lt;a href=&quot;#r2&quot;&gt;2&lt;/a&gt;]. Основная идея алгоритма – различное отношение к различным батчам
данных. Когда алгоритм идентифицирует, что модель недообучена для текущего батча данных, тогда размер шага обучения увеличивается, но при этом добавляется дополнительное ограничение,
которое позволяет избежать радикального изменения текущих весов модели. Эксперименты показывают, что ISGD сходится быстрее, чем классический SGD.
Например, при обучении нейронной сети AlexNet, ISGD на 21,05% быстрее чем SGD при достижении точности в 56%.&lt;/p&gt;

&lt;p&gt;Предложено использовать стохастический градиентный спуск с предварительным условием (Preconditioned Stochastic Gradient Descent), который использует особый вид предобуславлевателя (preconditioner) [&lt;a href=&quot;#r3&quot;&gt;3&lt;/a&gt;].
В некоторых случаях это позволяет обучить модель примерно в два раза быстрее.&lt;/p&gt;

&lt;p&gt;Предложен алгоритм разреженного обратного распространения ошибки (Sparsified Back Propagation) [&lt;a href=&quot;#r4&quot;&gt;4&lt;/a&gt;]. Суть алгоритма в том, что при обратном распространении ошибки
вычисляется только небольшое подмножество элементов полного градиента для обновления параметров модели.
Эксперименты авторов показывают, что можно обновлять только 1-4% от всех весов модели за каждую итерацию и при этом получить даже более высокую точность!
Это и не удивительно. Применение таких техник, как pruning, показывает, что можно удалить до 90% весов обученной нейронной сети и потерять лишь процентик точности.
Так зачем мы тратим ресурсы на вычисление градиента для такого огромного количества бесполезных в результате весов?&lt;/p&gt;

&lt;h3 id=&quot;Улучшение-моделей-машинного-обучения&quot;&gt;Улучшение моделей машинного обучения&lt;/h3&gt;

&lt;p&gt;В этой области не так много исследований. Не исключено, что я недостаточно качественно искал.&lt;/p&gt;

&lt;p&gt;Как правило, чем проще модель, тем быстрее она обучается и тем менее точно решает задачу. Однако, существуют техники, которые способны ускорить обучения без потери точности.
Одним из самых известных примеров является batch normalization [&lt;a href=&quot;#r5&quot;&gt;5&lt;/a&gt;]. Эта техника предложена в 2015 году и применена в нейронной сети Inception.
Суть техники заключается в применении нормализации к входным значениям различных слоев/блоков нейронной сети.
Применение этой техники позволяет Inception обучаться на данных ImageNet в 14 раз быстрее.&lt;/p&gt;

&lt;h3 id=&quot;Оптимизация-применения-алгоритмов-оптимизации&quot;&gt;Оптимизация применения алгоритмов оптимизации&lt;/h3&gt;

&lt;p&gt;В этом направлении очень широкое поле для творчества.
Из предложенных в 2017 году и уже применяемых на практике техник, самые известные – Snapshot Ensembles и FreezeOut.&lt;/p&gt;

&lt;p&gt;Подход Snapshot Ensembles [&lt;a href=&quot;#r6&quot;&gt;6&lt;/a&gt;] позволяет за один цикл обучения вместо одной модели получить целый ансамбль моделей.
Использование ансамблей – это популярная техника увеличения точности. Обычно она требует больших вычислительных ресурсов для обучения нескольких вариантов модели.
Snapshot Ensembles делает снэпшоты модели в различных локальных минимумах на протяжении одного цикла обучения.
Авторы опираются на то, что в различных локальных минимумах модель совершает, как правило, различные ошибки.
Таким образом, если агрегировать результаты моделей из различных локальных минимумов, можно получить лучшую итоговую точность.&lt;/p&gt;

&lt;p&gt;Метод FreezeOut позволяет увеличить скорость обучения путем последовательного “замораживания” весов сети по слоям [&lt;a href=&quot;#r7&quot;&gt;7&lt;/a&gt;] .
Авторы экспериментировали с последовательными заморозками слоев сети и показали, что это позволяет увеличить скорость обучения без потери точности.
Этот подход довольно быстро можно реализовать самостоятельно на любом фреймворке глубокого обучения.&lt;/p&gt;

&lt;h3 id=&quot;Заключение&quot;&gt;Заключение&lt;/h3&gt;

&lt;p&gt;В целом, существующие исследования в области ускорения обучения моделей выглядят многообещающе.
Некоторые методы можно использовать уже сейчас. А что применяете вы для ускорения обучения своих нейронных сетей?&lt;/p&gt;

&lt;p&gt;Ссылки:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a name=&quot;r1&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://arxiv.org/abs/1707.04822v1&quot;&gt;Normalized Gradient with Adaptive Stepsize Method for Deep Neural Network Training (arXiv:1707.04822)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;r2&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://arxiv.org/abs/1603.05544v3&quot;&gt;Accelerating Deep Neural Network Training with Inconsistent Stochastic Gradient Descent (arXiv:1603.05544)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;r3&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://arxiv.org/abs/1512.04202v3&quot;&gt;Preconditioned Stochastic Gradient Descent (arXiv:1512.04202)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;r4&quot;&gt;&lt;/a&gt; &lt;a href=&quot;http://proceedings.mlr.press/v70/sun17c.html&quot;&gt;meProp: Sparsified Back Propagation for Accelerated Deep Learning with Reduced Overfitting&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;r5&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://arxiv.org/abs/1502.03167&quot;&gt;Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift (arXiv:1502.03167)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;r6&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://arxiv.org/abs/1704.00109&quot;&gt;Snapshot Ensembles: Train 1, get M for free (arXiv:1704.00109)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;r7&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://arxiv.org/abs/1706.04983&quot;&gt;FreezeOut: Accelerate Training by Progressively Freezing Layers (arXiv:1706.04983)&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Андрей Хобня</name></author><category term="ML" /><category term="" /><summary type="html">Большинство последних улучшений и прорывов в машинном обучении происходило в основном в области создания моделей, которые обучаются лучше, чем их предшественники. При этом, чем точнее модель, тем, как правило, выше ее вычислительная сложность. Конечно, доступные вычислительные мощности растут, железо совершенствуется, развиваются оптимизированные под глубокое обучение библиотеки. Тем не менее, работа с наиболее передовыми моделями машинного обучения требует все большего количества ресурсов. Поэтому нам нужны не только более точные модели, но и более эффективные алгоритмы обучения. Какие исследования в данном направлении сейчас ведутся и что уже сделано?</summary></entry><entry><title type="html">Как изучать машинное обучение?</title><link href="https://aikho.github.io/2018/04/13/how-to-learn-machine-learning.html" rel="alternate" type="text/html" title="Как изучать машинное обучение?" /><published>2018-04-13T20:10:00+03:00</published><updated>2018-04-13T20:10:00+03:00</updated><id>https://aikho.github.io/2018/04/13/how-to-learn-machine-learning</id><content type="html" xml:base="https://aikho.github.io/2018/04/13/how-to-learn-machine-learning.html">&lt;p&gt;Меня часто спрашивают: как лучше всего изучать нейронные сети? Что почитать по нейронным сетям?
Есть множество курсов, которые обещают обучить вас нейронным сетям почти с нуля.
По моему мнению, для новичка такой подход может дать только поверхностные знания и вряд ли поможет развить навыки применения этих знаний в реальных задачах.
Перед тем как изучать глубокое обучение и современные нейронные сети, необходимо качественно изучить классическое машинное обучение!
Почему именно так?&lt;/p&gt;

&lt;p&gt;Потому, что качественное изучение основ машинного обучения даст вам систематизированные знания и понимание основополагающих принципов данной области.
А это, в свою очередь, даст вам следующие преимущества:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Вы сможете легко применять более простые подходы там, где нейронные сети просто не нужны, вместо того, чтобы каждый раз палить из пушки по воробьям.&lt;/li&gt;
  &lt;li&gt;Вы сможете быстрее изучать другие области и алгоритмы машинного обучения. Например бустинг, который в некоторых задачах может даже превосходить нейронные сети.&lt;/li&gt;
  &lt;li&gt;Вы будете более широко смотреть на машинное обучение. В лучшем случае, вы сможете самостоятельно улучшать модели и алгоритмы.&lt;/li&gt;
  &lt;li&gt;Вы лучше поймете глубокое обучение и нейронные сети и сможете лучше систематизировать свои знания в этой области.&lt;/li&gt;
  &lt;li&gt;Вы сможете применять классические модели машинного обучения вместе с глубокими нейронными сетями.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Я предлагаю новичкам изучать машинное обучение примерно в следующей последовательности.&lt;/p&gt;

&lt;h3 id=&quot;Изучите-или-вспомните-математику&quot;&gt;Изучите или вспомните математику&lt;/h3&gt;

&lt;p&gt;Повторите основы матана. Не сильно увлекайтесь тройными и эллиптическими интегралами, рядами, дифференциальными уравнениями. Повторите понятия частных производных,
градиента функции, непрерывности, монотонности, выпуклости, гладкости, областей определения и значения, локальных и глобальных экстремумов, седловых точек.&lt;/p&gt;

&lt;p&gt;Изучите или вспомните линейную алгебру. Не требуется становиться в этой области экспертом с ученой степенью, но вам необходимо знать и понимать основные понятия:
вектор, матрица, действия над векторами и матрицами, единичная матрица, векторные пространства, нормализация, факторизация, сингулярное разложение и т.д.&lt;/p&gt;

&lt;p&gt;Мне очень нравится книга Гилберта Стрэнга &lt;a href=&quot;https://www.amazon.com/Introduction-Linear-Algebra-Gilbert-Strang/dp/0980232775/&quot;&gt;Introduction to Linear Algebra&lt;/a&gt;.
Но вы можете взять и более короткую книгу.&lt;/p&gt;

&lt;p&gt;Приведите в порядок свои знания в статистике и теории вероятностей. Не обязательно защищать диссертацию по статистическим методам.
Изучите основы: случайные события, случайные величины, вероятность, распределение, основные виды распределений (нормальное, экспоненциальное, равномерное, логнормальное и т.д.),
плотность вероятности, корреляция, ковариация, выборка, дисперсия, ошибка выборки, условная вероятность, теорема Байеса, метод наименьших квадратов.&lt;/p&gt;

&lt;p&gt;Мне нравится книга &lt;a href=&quot;http://greenteapress.com/wp/think-stats-2e/&quot;&gt;Think Stats: Exploratory Data Analysis&lt;/a&gt;.
Она написана для разработчиков, содержит примеры кода на Python. Объясняет простым английским языком основные теоретические понятия и одновременно позволяет изучить
библиотеки NumPy, SciPy, pandas, matplotlib и StatsModels. Первые 10 глав покрывают все необходимые темы. Кроме того, эта книга официально находится в свободном доступе.&lt;/p&gt;

&lt;p&gt;Изучив эти разделы математики вы не только заложите прочный фундамент для освоения машинного обучения, но и прокачаете свой мозг, и получите знания, которые можно использовать практически в любой области от страхования до квантовой механики.&lt;/p&gt;

&lt;h3 id=&quot;Изучите-основы-машинного-обучения&quot;&gt;Изучите основы машинного обучения&lt;/h3&gt;

&lt;p&gt;Начните с понятия машинного обучение. Изучите какие бывают типы машинного обучения: с учителем, без учителя, с частичным привлечением учителя, с подкреплением.
Узнайте какие бывают задачи машинного обучения: классификация, регрессия, кластеризация и т.д.&lt;/p&gt;

&lt;p&gt;Изучите линейную регрессию и метод градиентного спуска.
Разберитесь с понятиями “модель машинного обучения” и “алгоритм машинного обучения”.
Изучите понятие функции ошибки и принципы валидации моделей машинного обучения.
Разберитесь со стохастическим градиентным спуском.&lt;/p&gt;

&lt;p&gt;Изучите логистическую регрессию, бинарную и многоклассовую классификацию.
Усвойте понятия переобучения и недообучения, F1-score, стратегии валидации, K-Fold валидацию,
основные методы регуляризации.
Разберитесь с каким-нибудь продвинутым методом оптимизации, например BFGS.&lt;/p&gt;

&lt;p&gt;Изучите парочку более сложных моделей машинного обучения для классификации.
Например, наивный байесовский классификатор и машины опорных векторов.
Разберитесь с понятием “feature engineering”. Усвойте No free lunch theorem.&lt;/p&gt;

&lt;p&gt;Изучите основы нейронных сетей: нейрон, функции активации, слой,
алгоритм обратного распространения ошибки, перцептрон.&lt;/p&gt;

&lt;p&gt;Разберитесь с обучением без учителя: кластеризация, уменьшение размерности данных,
метод k-средних, метод главных компонент (PCA), анализ независимых компонент (ICA),
поиск выбросов и аномалий в данных.&lt;/p&gt;

&lt;p&gt;По последовательности и ясности изложения материала мне очень нравится курс Andrew Ng &lt;a href=&quot;https://www.coursera.org/learn/machine-learning&quot;&gt;Machine learning&lt;/a&gt;.
Но минус этого курса в том, что в нем не рассматриваются конкретные инструменты машинного обучения, которые сейчас используются на практике.&lt;/p&gt;

&lt;p&gt;Поэтому я рекомендую также изучать библиотеку &lt;a href=&quot;http://scikit-learn.org/stable/&quot;&gt;scikit-learn&lt;/a&gt;.
Она достаточно популярна на сегодняшний день, реализует основные модели классического машинного обучения. На официальном сайте есть множество туториалов.
Также можно изучать ее по первой части книги &lt;a href=&quot;https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1491962291&quot;&gt;Hands-On Machine Learning with Scikit-Learn and TensorFlow&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;Переходите-к-глубокому-машинному-обучению&quot;&gt;Переходите к глубокому машинному обучению&lt;/h3&gt;

&lt;p&gt;Сегодня это развивающаяся область, поэтому ни в одной книге вы не получите полный обзор всех значительных достижений в теории глубокого обучения.
Но, в любом случае, необходимо начать с основ: глубокие нейронные сети прямого распространения, сверточные нейронные сети, проблема исчезающего градиента, ReLU,
градиентный спуск с моментом, рекуррентные нейронные сети, LSTM  и т.д.&lt;/p&gt;

&lt;p&gt;Для изучения теории глубокого обучения рекомендую замечательную книгу Айана Гудфеллоу и соавторов: &lt;a href=&quot;http://www.deeplearningbook.org/&quot;&gt;Deep Learning&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Для овладения практическими навыками необходимо изучить какой-нибудь Deep Learning фреймворк. Проще всего начать с фреймворков-конструкторов, например &lt;a href=&quot;https://keras.io/&quot;&gt;Keras&lt;/a&gt;.
Затем можно переходить к более низкоуровневым фреймворкам, например &lt;a href=&quot;https://www.tensorflow.org/&quot;&gt;Tensorflow&lt;/a&gt;.
Можно изучать его по второй части книги &lt;a href=&quot;https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1491962291&quot;&gt;Hands-On Machine Learning with Scikit-Learn and TensorFlow&lt;/a&gt;.
Также есть отличная специализация из 5 видео-курсов &lt;a href=&quot;https://www.coursera.org/specializations/deep-learning&quot;&gt;Deep Learning&lt;/a&gt; от Andrew Ng.
Затем можно переходить к изучению более продвинутых и специализированных вещей.&lt;/p&gt;

&lt;h3 id=&quot;Заключение&quot;&gt;Заключение&lt;/h3&gt;

&lt;p&gt;По моему мнению, именно описанный выше подход позволит получить систематизированные знания и развить навыки применения этих знаний в реальных задачах.
Возможно, я упустил какие-нибудь темы. Также я допускаю, что у другого опытного специалиста может быть отличное от моего мнение по поводу того, как правильно изучать машинное обучение.
Если у вас есть какие-либо ремарки или вопросы, добро пожаловать в комментарии.&lt;/p&gt;</content><author><name>Андрей Хобня</name></author><category term="ML" /><category term="Tutorial" /><summary type="html">Меня часто спрашивают: как лучше всего изучать нейронные сети? Что почитать по нейронным сетям? Есть множество курсов, которые обещают обучить вас нейронным сетям почти с нуля. По моему мнению, для новичка такой подход может дать только поверхностные знания и вряд ли поможет развить навыки применения этих знаний в реальных задачах. Перед тем как изучать глубокое обучение и современные нейронные сети, необходимо качественно изучить классическое машинное обучение! Почему именно так?</summary></entry><entry><title type="html">Насколько универсальна AlphaZero?</title><link href="https://aikho.github.io/2018/04/06/how-universal-is-alpha-zero.html" rel="alternate" type="text/html" title="Насколько универсальна AlphaZero?" /><published>2018-04-06T12:30:00+03:00</published><updated>2018-04-06T12:30:00+03:00</updated><id>https://aikho.github.io/2018/04/06/how-universal-is-alpha-zero</id><content type="html" xml:base="https://aikho.github.io/2018/04/06/how-universal-is-alpha-zero.html">&lt;p&gt;Многие представляют &lt;a href=&quot;https://ru.wikipedia.org/wiki/AlphaZero&quot;&gt;AlphaZero&lt;/a&gt; как некий искусственный интеллект, который способен автоматически без участия человека обучиться выигрывать в любую игру.
Достаточно лишь “объяснить” ей правила. Но так ли это на самом деле? И что значит “объяснить” правила игры AlphaZero?
В этом нам поможет разобраться оригинальная публикация разработчиков системы.&lt;/p&gt;

&lt;p&gt;Итак, откроем статью об AlphaZero на ArXiv.org [&lt;a href=&quot;#r1&quot;&gt;1&lt;/a&gt;] и перейдем сразу к разделу &lt;strong&gt;Domain Knowledge&lt;/strong&gt; на странице 12. Мы видим всего 5 пунктов.
Давайте прочитаем их внимательно и попытаемся проанализировать. Итак, пункт первый:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;1.The input features describing the position, and the output features describing the move,
are structured as a set of planes; i.e. the neural network architecture is matched to the
grid-structure of the board.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Входные данные позиции игры представляются как множество плоскостей, и архитектура нейронной сети соответствует структуре сетки доски.&lt;/p&gt;

&lt;p&gt;Это простое замечание уже вызывает много интересных вопросов. В шахматах, го и сеги доска представляет собой квадратную сетку.
Это очень удобно для сверточных нейронных сетей. Фильтры в сверточных сетях – это тоже сетки квадратной или прямоугольной формы.
Сверточные сети хорошо подходят для входных данных в виде матрицы. Но что, если взять игру с доской другой формы? Например, китайские шашки или затрикион?
В этом случае придется существенно переработать существующие подходы к проектированию архитектуры нейронной сети для AlphaZero.&lt;/p&gt;

&lt;p&gt;Кроме того, для каждой новой игры скорее всего потребуется спроектировать свою структуру скрытых слоев сети.
В статье авторы утверждают, что AlphaZero использует одну и ту же архитектуру нейронной сети для всех трех игр:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Unless otherwise specified,
the same algorithm settings, network architecture, and hyper-parameters were used for all
three games.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Здесь есть некоторое противоречие с пунктом номер 1. Скорее всего, имеется ввиду, что различаются лишь входные и выходные слои нейронной сети,
а скрытые слои имеют одинаковую структуру. Такой подход может работать, если разработчики подобрали архитектуру, которая приемлемо работает для всех трех игр.
Однако, не исключено, что авторы могли добиться лучших результатов, если бы использовали отдельные оптимизированные для каждой игры архитектуры.
То, что хорошо работает для одной игры, может не работать (или работать хуже) для другой. No free lunch [&lt;a href=&quot;#r2&quot;&gt;2&lt;/a&gt;].
Поэтому, вполне вероятно, что, чтобы обучить AplhaZero непохожей на го и шахматы игре на доске странной формы, понадобится спроектировать новую нейронную сеть.
Каким образом это сделать? Какое количество и размер фильтров использовать в каждом сверточном слое?
Ответ на это вопрос такой же как и для любой другой задачи машинного обучения. Никто не знает!
Это творческий процесс, включающий в себя инженерию, науку и интуицию. 
В любом случае, придется поэкспериментировать, вряд ли оптимальная архитектура получится с первой попытки.
Поскольку процесс обучения с подкреплением требует большого количества ресурсов, для экспериментов с архитектурой нейронной сети практичней использовать базу данных сыгранных партий.
Разработчики AlphaZero уже имели опыт обучения сети на партиях го.
Использовали ли они базы данных партий для предварительной оптимизации архитектуры сети в случае AlphaZero?
В статье этот вопрос не освещается.&lt;/p&gt;

&lt;p&gt;Но перейдем к следующему пункту:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;2.AlphaZero is provided with perfect knowledge of the game rules. These are used during
MCTS, to simulate the positions resulting from a sequence of moves, to determine game
termination, and to score any simulations that reach a terminal state.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Возможные ходы и проверка условий завершения игры “жестко” запрограммированы и используются при поиске по дереву методом Монте-Карло.&lt;/p&gt;

&lt;p&gt;Здесь стоит пояснить, что AlphaZero не использует end-to-end модель машинного обучения. Это гибридная система.
Она использует нейронную сеть для предсказания наиболее вероятных ходов и оценки позиции. А поиск по дереву методом Монте-Карло используется для выбора лучшего хода.
Фактически, архитектура AlphaZero похожа на архитектуру классических игровых AI-движков. 
Но вместо алгоритма альфа-бета отсечения используется более общий алгоритм Монте-Карло поиска по дереву, а вместо запрограммированной эвристической функции оценки, используется сложная нейронная сеть.
По моему мнению, это очень правильный практичный подход. Однако, его применение требует ручного программирования перебора возможных ходов и различных условий правил.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;3.Knowledge of the rules is also used to encode the input planes (i.e. castling, repetition,
no-progress) and output planes (how pieces move, promotions, and piece drops in shogi).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Знание правил также закодировано во входных и выходных плоскостях (матрицах).&lt;/p&gt;

&lt;p&gt;Это самый интересный пункт. Чтобы понять, что именно имеется в виду, необходимо обратиться к следующему разделу статьи – &lt;strong&gt;Representation&lt;/strong&gt;.
В этом разделе описаны входные и выходные матрицы нейронной сети для каждой игры и приведена сводная таблица.
Если мы посмотрим в эту таблицу, то увидим, что, например, для шахмат в качестве входных данных позиции используется 119 матриц.
119 матриц?! Почему так много? Чтобы разобраться в этом, прочитаем пояснения в данном разделе.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;The M feature planes are composed
 of binary feature planes indicating the presence of the player’s pieces, with one plane for each
 piece type, and a second set of planes indicating the presence of the opponent’s pieces.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Значит используются двоичные матрицы, по одной для каждого типа фигур. Столько же матриц используется для фигур противоположного цвета.
В шахматах 6 типов фигур, значит получается 12 матриц для фигур двух противников.
В таблице также указано еще две матрицы для количества повторений позиции. Это необходимо для учета правила троекратного повторения.
Получается уже 14 матриц.
Однако, кроме последней позиции фигур, передаются еще несколько предшествующих позиций:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;The first set of features are repeated for each position in a T = 8-step history.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Первое множество атрибутов повторяется для каждой из восьми предшествующих позиций. Т.е. мы имеем уже не 14 матриц, а 14*8=112 матриц.
Остальные 7 матриц используются для кодирования текущего цвета, номера текущего хода, рокировок и количества обратимых ходов.
Почему именно 8 предшествующих позиций и как авторы получили данное число? В статье это не уточняется.
Нам известно лишь, что данное значение хорошо работает для всех трех игр.
Возможно, значение 8 будет хорошо работать и для других игр, но чтобы это выяснить, необходимо отдельное исследование.&lt;/p&gt;

&lt;p&gt;Интересно также как представляются выходные данные. Если посмотреть в сводную таблицу, мы увидим, что ход в шахматах кодируется для AlphaZero при помощи 73 матриц.
Вот как описывают это авторы:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;A move in chess may be described in two parts: selecting the piece to move, and then
selecting among the legal moves for that piece. We represent the policy π(a|s) by a 8 × 8 × 73
stack of planes encoding a probability distribution over 4,672 possible moves. Each of the 8×8
positions identifies the square from which to “pick up” a piece. The first 56 planes encode
possible ‘queen moves’ for any piece: a number of squares [1..7] in which the piece will be
moved, along one of eight relative compass directions {N, NE, E, SE, S, SW, W, NW}. The
next 8 planes encode possible knight moves for that piece. The final 9 planes encode possible
underpromotions for pawn moves or captures in two possible diagonals, to knight, bishop or
rook respectively. Other pawn moves or captures from the seventh rank are promoted to a
queen.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Ход в шахматах можно описать при помощи двух составляющих: позиции фигуры, которой делается ход, и возможного хода для данной фигуры.
Итак, первые 56 матриц кодируют возможные ходы ферзя для любой фигуры. Почему 56 и что значит “ходы ферзя для любой фигуры”?
Ферзь может ходить в восьми направлениях. Его можно передвинуть на любое количество клеток от 1 до 7.
Получаем 7*8=56 возможных ходов. Пешки, ладьи, слоны и короли могут совершать некоторые из этих 56 ходов. Поэтому те же самые 56 матриц используются и для этих фигур.
Кони ходят другим способом. Поэтому следующие 8 матриц кодируют ходы коней.
Последние 9 матриц кодируют превращения пешек в коней, слонов и ладей. Почему именно 9 матриц?
Пешка может попасть на последнюю горизонталь тремя способами: ходом вперед, взятием фигуры по диагонали слева и взятием фигуры по диагонали справа.
Кодируется три вида превращений: в коня, в слона и в ладью. Получается 9 возможных ходов.
Остальные ходы пешек на последнюю горизонталь (те самые, которые кодируются первыми 56 матрицами) считаются превращением в ферзей.
Таким образом, получаем в сумме 73 матрицы.&lt;/p&gt;

&lt;p&gt;Как видим, в AlphaZero используются довольно сложные специфические представления игровых позиций и ходов.
Неизвестно, каким образом авторы пришли именно к таким представлениям.
Адаптация AlphaZero для новой игры потребует разработки своих представлений позиций и ходов в игре.
Если судить по представленному выше разбору, это может быть достаточно нетривиальной задачей.&lt;/p&gt;

&lt;p&gt;Рассмотрим оставшиеся пункты:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;4.The typical number of legal moves is used to scale the exploration noise (see below).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Типичное количество правильных ходов использовано для масштабирования параметра шума.&lt;/p&gt;

&lt;p&gt;Добавление шума в обучении с подкреплением используется для создания компромисса между исследованием неизученных областей и применением имеющихся знаний агента.
В данном случае используется дополнительная информация об игре (типичное количество правильных ходов в позиции) для пропорционального масштабирования параметра шума для данной игры.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;5.Chess and shogi games exceeding a maximum number of steps (determined by typical
game length) were terminated and assigned a drawn outcome; Go games were terminated
and scored with Tromp-Taylor rules, similarly to previous work (29)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Для шахмат и сеги игра останавливается с ничейным результатом при превышении максимального количества ходов, равного типичной длине партии.&lt;/p&gt;

&lt;p&gt;Справедливости ради стоит заметить, что типичная длина партии не является частью правил игры, а является дополнительной информацией. 
Скорее всего, этот параметр используется для упрощения и ускорения обучения.
Нет смысла ограничивать длину партии только для защиты от перебора бесконечных последовательностей ходов.
В современных шахматах существует правило 50 ходов [&lt;a href=&quot;#r3&quot;&gt;3&lt;/a&gt;], которое позволяет игроку объявить ничью, если последние 50 ходов были сделаны каждым игроком без перемещения пешек и без взятия любой фигуры.
Кроме того, из статьи не ясно, каким образом авторы вычислили типичную длину партии.
Возможно для этого использовались базы партий или другие данные.&lt;/p&gt;

&lt;h3 id=&quot;Выводы&quot;&gt;Выводы&lt;/h3&gt;

&lt;p&gt;AlphaZero – это безусловно прорыв, который продемонстрировал возможности и перспективы глубокого обучения с подкреплением.
Однако, адаптация AlphaZero для других игр и задач достаточно сложна и потребует усилий по программированию перебора ходов и условий правил, исследованию и проектированию нейронных сетей.
AlphaZero не может автоматически “настроиться” на новую игру. В будущих статьях я планирую показать, каким образом можно построить похожую систему 
и обучить ее выигрывать в какой-нибудь экзотической или придуманной игре.&lt;/p&gt;

&lt;p&gt;А что вы думаете про AlphaZero? Является ли AlphaZero шагом к генерализированному AI или удачно спроектированной для трех игр специализированной гибридной системой?&lt;/p&gt;

&lt;p&gt;Ссылки:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a name=&quot;r1&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://arxiv.org/pdf/1712.01815.pdf&quot;&gt;Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;r2&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://en.wikipedia.org/wiki/No_free_lunch_theorem&quot;&gt;No free lunch theorem&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;r3&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://ru.wikipedia.org/wiki/%D0%9F%D1%80%D0%B0%D0%B2%D0%B8%D0%BB%D0%BE_50_%D1%85%D0%BE%D0%B4%D0%BE%D0%B2&quot;&gt;Правило 50 ходов&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Андрей Хобня</name></author><category term="ML" /><category term="RL" /><summary type="html">Многие представляют AlphaZero как некий искусственный интеллект, который способен автоматически без участия человека обучиться выигрывать в любую игру. Достаточно лишь “объяснить” ей правила. Но так ли это на самом деле? И что значит “объяснить” правила игры AlphaZero? В этом нам поможет разобраться оригинальная публикация разработчиков системы.</summary></entry><entry><title type="html">Успехи машинного обучения в цифрах</title><link href="https://aikho.github.io/2018/04/01/measurable-successes-of-ml.html" rel="alternate" type="text/html" title="Успехи машинного обучения в цифрах" /><published>2018-04-01T20:16:51+03:00</published><updated>2018-04-01T20:16:51+03:00</updated><id>https://aikho.github.io/2018/04/01/measurable-successes-of-ml</id><content type="html" xml:base="https://aikho.github.io/2018/04/01/measurable-successes-of-ml.html">&lt;p&gt;Машинное обучение позволяет решать многие задачи гораздо эффективнее других подходов.
Какого типа эти задачи и насколько существенно машинное обучение превосходит иные методы? 
Есть множество примеров успешного применения машинного обучения. Но, как говорил Менделеев, “наука начинается там, где начинается измерение.”
Поэтому я сделал небольшую подборку успехов машинного обучения с конкретными цифрами.&lt;/p&gt;

&lt;h3 id=&quot;1-ilsvrc-imagenet&quot;&gt;1. ILSVRC (ImageNet)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://aikho.github.io/assets/img/2018-04-01-measurable-successes-of-ml/fig1.jpeg&quot; alt=&quot;Изображения ImageNet&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Это первый пример, который приходит в голову. ILSVRC (ImageNet Large Scale Visual Recognition Challenge) – известные ежегодные соревнования систем компьютерного зрения, на которых команды исследователей со всего мира соревнуются в разработке систем для решения задач классификации, локализации и обнаружения объектов на изображениях.
В 2012 году первое место с top-5 error &lt;strong&gt;15.4%&lt;/strong&gt; заняла сверточная нейронная сеть AlexNet [&lt;a href=&quot;#r1&quot;&gt;1&lt;/a&gt;]. При этом второе место заняла система с top-5 error &lt;strong&gt;26.2%&lt;/strong&gt;!
Такая огромная разбежка в результатах потрясла сообщество исследователей компьютерного зрения и стала начальным рубежом эпохи глубокого обучения.&lt;/p&gt;

&lt;p&gt;C 2012 года архитектуры сверточных нейронных сетей существенно продвинулись. 
В 2015 году нейронная сеть ResNet от Microsoft Research Asia достигла top-5 error &lt;strong&gt;3.6%&lt;/strong&gt;!
Значительный результат, учитывая что человек в данном соревновании способен показать top-5 error на уровне 5-10% [&lt;a href=&quot;#r2&quot;&gt;2&lt;/a&gt;].
Но и этот результат был превзойден. В 2017 году нейронные сети достигли top-5 error &lt;strong&gt;2.3%&lt;/strong&gt; [&lt;a href=&quot;#r3&quot;&gt;3&lt;/a&gt;]!&lt;/p&gt;

&lt;h3 id=&quot;2-Анализ-дермоскопических-изображений&quot;&gt;2. Анализ дермоскопических изображений&lt;/h3&gt;
&lt;p&gt;В 2017 году в журнале Nature опубликованы результаты исследовательского проекта разработки алгоритмов анализа дермоскопических изображений [&lt;a href=&quot;#r4&quot;&gt;4&lt;/a&gt;].
Исследователи использовали глубокие сверточные нейронные сети для машинного обучения бинарной классификации между похожими доброкачественными и злокачественными образованиями кожи.
В результате была достигнута точность классификации &lt;strong&gt;72,1%&lt;/strong&gt;, в то время как два привлеченных дерматолога смогли справиться с данной задачей только в &lt;strong&gt;65,56%&lt;/strong&gt; случаев!
Возможно, именно машинное обучение сыграет одну из ключевых ролей в победе над раком кожи!&lt;/p&gt;

&lt;h3 id=&quot;3-Обнаружение-метастазов-на-микроскопических-изображениях&quot;&gt;3. Обнаружение метастазов на микроскопических изображениях&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://aikho.github.io/assets/img/2018-04-01-measurable-successes-of-ml/fig2.png&quot; alt=&quot;Пример&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Еще один впечатляющий пример применения машинного обучения в медицине. Исследователи представили фреймворк, позволяющий обнаруживать раковые опухоли 100x100 пикселей на гигапиксельных микроскопических изображениях размером 100’000x100’000 пикселей.
Их способ использует глубокие сверточные нейронные сети и достигает точности &lt;strong&gt;92.4%&lt;/strong&gt;. До этого лучший автоматический метод работал с точностью &lt;strong&gt;82.7%&lt;/strong&gt;, а специалист в области патологий достиг точности &lt;strong&gt;73.2%&lt;/strong&gt; [&lt;a href=&quot;#r5&quot;&gt;5&lt;/a&gt;].&lt;/p&gt;

&lt;h3 id=&quot;4-Игра-го&quot;&gt;4. Игра го&lt;/h3&gt;
&lt;p&gt;Если в шахматы компьютерные программы играют лучше людей с 1997 года, то в игре го они долгое время даже близко не могли подобраться к победе над гроссмейстерами.
Но машинное обучение изменило положение вещей. 
В марте 2016 года система AlphaGo, основанная на глубоком машинном обучении и методе Монте-Карло для поиска в дереве, выиграла со счётом &lt;strong&gt;4—1&lt;/strong&gt; у Ли Седоля [&lt;a href=&quot;#r6&quot;&gt;6&lt;/a&gt;], многократного чемпиона мира по го.
В 2017 году улучшенная версия системы AlphaGo Master провела несколько показательных игр и победила во всех, в том числе в игре против команды из пяти профессионалов максимального 9 дана [&lt;a href=&quot;#r7&quot;&gt;7&lt;/a&gt;].&lt;/p&gt;

&lt;h3 id=&quot;5-Шахматы&quot;&gt;5. Шахматы&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://aikho.github.io/assets/img/2018-04-01-measurable-successes-of-ml/fig4.png&quot; alt=&quot;Пример&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Разработчики AlphaGo создали обобщенный вариант системы —— AlphaZero, который кроме го, умеет также играть в шахматы и сеги.
Долгое время одним из сильнейших шахматных движков считался Stockfish. Из 100 игр против Stockfish с нормальным начальным положением AlphaZero выиграл 25 партий белыми, 3 чёрными и свёл вничью оставшиеся 72 [&lt;a href=&quot;#r8&quot;&gt;8&lt;/a&gt;].&lt;/p&gt;

&lt;h3 id=&quot;6-Фильтрация-спама&quot;&gt;6. Фильтрация спама&lt;/h3&gt;
&lt;p&gt;Наверное одно из самых первых комерческих применений классического машинного обучения. В 2002 году Пол Грэм писал, что, согласно исследованиям, самый лучший на тот момент спам-фильтр на основе ключевых слов определяет только &lt;strong&gt;24%&lt;/strong&gt; спама при &lt;strong&gt;34%&lt;/strong&gt; ложноположительных срабатываний [&lt;a href=&quot;#r9&quot;&gt;9&lt;/a&gt;].
При этом его метод фильтрации спама на основе Байесовского классификатора правильно определял &lt;strong&gt;99.5%&lt;/strong&gt; спама c &lt;strong&gt;0%&lt;/strong&gt; ложноположительных срабатываний [&lt;a href=&quot;#r10&quot;&gt;10&lt;/a&gt;].&lt;/p&gt;

&lt;h3 id=&quot;Вывод&quot;&gt;Вывод&lt;/h3&gt;
&lt;p&gt;Анализ этих примеров позволяет лучше понимать, в каких задачах машинное обучение работает эффективнее всего.
Объективно, это не творческие задачи, в данных задачах необходимо на основе входных данных выбрать верное решение из некоторого ограниченного множества возможных решений.
Но это те задачи, для которых не существует четких алгоритмов и правил, позволяющих гарантировано получить верный ответ.
Обычно для таких задач используются различные эвристические методы. И машинное обучение во многих случаях позволяет на основе данных получить лучшие эвристики, которые значительно превосходят спроектированные вручную алгоритмы.
Поэтому именно машинное обучение позволит нам подойти к решению таких задач, о которых мы раньше не осмеливались и думать!&lt;/p&gt;

&lt;p&gt;Ссылки:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a name=&quot;r1&quot;&gt;&lt;/a&gt; &lt;a href=&quot;http://image-net.org/challenges/LSVRC/2012/results.html&quot;&gt;Результаты LSVRC 2012.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;r2&quot;&gt;&lt;/a&gt; &lt;a href=&quot;http://karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/&quot;&gt;Замечательная статья Андрея Карпатого о ручном распознавании изображений ImageNet.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;r3&quot;&gt;&lt;/a&gt; &lt;a href=&quot;http://image-net.org/challenges/LSVRC/2017/results&quot;&gt;Результаты LSVRC 2017.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;r4&quot;&gt;&lt;/a&gt; A. Esteva, B. Kuprel, R.A. Novoa, J. Ko, S.M. Swetter, H.M. Blau , S. Thrun. Dermatologist-level classification of skin cancer with deep neural networks. Nature 542, 115–118 (2017)&lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;r5&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://arxiv.org/abs/1703.02442&quot;&gt;Detecting Cancer Metastases on Gigapixel Pathology Images (arXiv:1703.02442)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;r6&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://www.wired.com/2016/03/final-game-alphago-lee-sedol-big-deal-humanity/&quot;&gt;Why the Final Game Between AlphaGo and Lee Sedol Is Such a Big Deal for Humanity&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;r7&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://www.wired.co.uk/article/deepmind-go-alphago-china-may-2017&quot;&gt;AlphaGo takes the series title&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;r8&quot;&gt;&lt;/a&gt; &lt;a href=&quot;http://www.bbc.com/news/technology-42251535&quot;&gt;‘Superhuman’ Google AI claims chess crown&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;r9&quot;&gt;&lt;/a&gt; &lt;a href=&quot;http://www.paulgraham.com/falsepositives.html&quot;&gt;Paul Graham. Filters vs. Blacklists&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;r10&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://www.infoworld.com/article/2674702/technology-business/techology-business-paul-graham-provides-stunning-answer-to-spam-e-mails.html&quot;&gt;Paul Graham provides stunning answer to spam e-mails&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Андрей Хобня</name></author><category term="ML" /><category term="Будущее" /><summary type="html">Машинное обучение позволяет решать многие задачи гораздо эффективнее других подходов. Какого типа эти задачи и насколько существенно машинное обучение превосходит иные методы? Есть множество примеров успешного применения машинного обучения. Но, как говорил Менделеев, “наука начинается там, где начинается измерение.” Поэтому я сделал небольшую подборку успехов машинного обучения с конкретными цифрами.</summary></entry></feed>