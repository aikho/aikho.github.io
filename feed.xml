<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.3">Jekyll</generator><link href="https://aikho.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://aikho.github.io/" rel="alternate" type="text/html" /><updated>2018-04-13T20:19:22+03:00</updated><id>https://aikho.github.io/</id><title type="html">AIkho.github.io</title><subtitle>Блог о машинном обучении и разработке интеллектуальных систем</subtitle><author><name>Андрей Хобня</name></author><entry><title type="html">Как изучать машинное обучение?</title><link href="https://aikho.github.io/2018/04/13/how-to-learn-machine-learning.html" rel="alternate" type="text/html" title="Как изучать машинное обучение?" /><published>2018-04-13T20:10:00+03:00</published><updated>2018-04-13T20:10:00+03:00</updated><id>https://aikho.github.io/2018/04/13/how-to-learn-machine-learning</id><content type="html" xml:base="https://aikho.github.io/2018/04/13/how-to-learn-machine-learning.html">&lt;p&gt;Меня часто спрашивают: как лучше всего изучать нейронные сети? Что почитать по нейронным сетям?
Есть множество курсов, которые обещают обучить вас нейронным сетям почти с нуля.
По моему мнению, для новичка такой подход может дать только поверхностные знания и вряд ли поможет развить навыки применения этих знаний в реальных задачах.
Перед тем как изучать глубокое обучение и современные нейронные сети, необходимо качественно изучить классическое машинное обучение!
Почему именно так?&lt;/p&gt;

&lt;p&gt;Потому, что качественное изучение основ машинного обучения даст вам систематизированные знания и понимание основополагающих принципов данной области.
А это, в свою очередь, даст вам следующие преимущества:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Вы сможете легко применять более простые подходы там, где нейронные сети просто не нужны, вместо того, чтобы каждый раз палить из пушки по воробьям.&lt;/li&gt;
  &lt;li&gt;Вы сможете быстрее изучать другие области и алгоритмы машинного обучения. Например бустинг, который в некоторых задачах может даже превосходить нейронные сети.&lt;/li&gt;
  &lt;li&gt;Вы будете более широко смотреть на машинное обучение. В лучшем случае, вы сможете самостоятельно улучшать модели и алгоритмы.&lt;/li&gt;
  &lt;li&gt;Вы лучше поймете глубокое обучение и нейронные сети и сможете лучше систематизировать свои знания в этой области.&lt;/li&gt;
  &lt;li&gt;Вы сможете применять классические модели машинного обучения вместе с глубокими нейронными сетями.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Я предлагаю новичкам изучать машинное обучение примерно в следующей последовательности.&lt;/p&gt;

&lt;h3 id=&quot;Изучите-или-вспомните-математику&quot;&gt;Изучите или вспомните математику&lt;/h3&gt;

&lt;p&gt;Повторите основы матана. Не сильно увлекайтесь тройными и эллиптическими интегралами, рядами, дифференциальными уравнениями. Повторите понятия частных производных,
градиента функции, непрерывности, монотонности, выпуклости, гладкости, областей определения и значения, локальных и глобальных экстремумов, седловых точек.&lt;/p&gt;

&lt;p&gt;Изучите или вспомните линейную алгебру. Не требуется становиться в этой области экспертом с ученой степенью, но вам необходимо знать и понимать основные понятия:
вектор, матрица, действия над векторами и матрицами, единичная матрица, векторные пространства, нормализация, факторизация, сингулярное разложение и т.д.&lt;/p&gt;

&lt;p&gt;Мне очень нравится книга Гилберта Стрэнга &lt;a href=&quot;https://www.amazon.com/Introduction-Linear-Algebra-Gilbert-Strang/dp/0980232775/&quot;&gt;Introduction to Linear Algebra&lt;/a&gt;.
Но вы можете взять и более короткую книгу.&lt;/p&gt;

&lt;p&gt;Приведите в порядок свои знания в статистике и теории вероятностей. Не обязательно защищать диссертацию по статистическим методам.
Изучите основы: случайные события, случайные величины, вероятность, распределение, основные виды распределений (нормальное, экспоненциальное, равномерное, логнормальное и т.д.),
плотность вероятности, корреляция, ковариация, выборка, дисперсия, ошибка выборки, условная вероятность, теорема Байеса, метод наименьших квадратов.&lt;/p&gt;

&lt;p&gt;Мне нравится книга &lt;a href=&quot;http://greenteapress.com/wp/think-stats-2e/&quot;&gt;Think Stats: Exploratory Data Analysis&lt;/a&gt;.
Она написана для разработчиков, содержит примеры кода на Python. Объясняет простым английским языком основные теоретические понятия и одновременно позволяет изучить
библиотеки NumPy, SciPy, pandas, matplotlib и StatsModels. Первые 10 глав покрывают все необходимые темы. Кроме того, эта книга официально находится в свободном доступе.&lt;/p&gt;

&lt;p&gt;Изучив эти разделы математики вы не только заложите прочный фундамент для освоения машинного обучения, но и прокачаете свой мозг, и получите знания, которые можно использовать практически в любой области от страхования до квантовой механики.&lt;/p&gt;

&lt;h3 id=&quot;Изучите-основы-машинного-обучения&quot;&gt;Изучите основы машинного обучения&lt;/h3&gt;

&lt;p&gt;Начните с понятия машинного обучение. Изучите какие бывают типы машинного обучения: с учителем, без учителя, с частичным привлечением учителя, с подкреплением.
Узнайте какие бывают задачи машинного обучения: классификация, регрессия, кластеризация и т.д.&lt;/p&gt;

&lt;p&gt;Изучите линейную регрессию и метод градиентного спуска.
Разберитесь с понятиями “модель машинного обучения” и “алгоритм машинного обучения”.
Изучите понятие функции ошибки и принципы валидации моделей машинного обучения.
Разберитесь со стохастическим градиентным спуском.&lt;/p&gt;

&lt;p&gt;Изучите логистическую регрессию, бинарную и многоклассовую классификацию.
Усвойте понятия переобучения и недообучения, F1-score, стратегии валидации, K-Fold валидацию,
основные методы регуляризации.
Разберитесь с каким-нибудь продвинутым методом оптимизации, например BFGS.&lt;/p&gt;

&lt;p&gt;Изучите парочку более сложных моделей машинного обучения для классификации.
Например, наивный байесовский классификатор и машины опорных векторов.
Разберитесь с понятием “feature engineering”. Усвойте No free lunch theorem.&lt;/p&gt;

&lt;p&gt;Изучите основы нейронных сетей: нейрон, функции активации, слой,
алгоритм обратного распространения ошибки, перцептрон.&lt;/p&gt;

&lt;p&gt;Разберитесь с обучением без учителя: кластеризация, уменьшение размерности данных,
метод k-средних, метод главных компонент (PCA), анализ независимых компонент (ICA),
поиск выбросов и аномалий в данных.&lt;/p&gt;

&lt;p&gt;По последовательности и ясности изложения материала мне очень нравится курс Andrew Ng &lt;a href=&quot;https://www.coursera.org/learn/machine-learning&quot;&gt;Machine learning&lt;/a&gt;.
Но минус этого курса в том, что в нем не рассматриваются конкретные инструменты машинного обучения, которые сейчас используются на практике.&lt;/p&gt;

&lt;p&gt;Поэтому я рекомендую также изучать библиотеку &lt;a href=&quot;http://scikit-learn.org/stable/&quot;&gt;scikit-learn&lt;/a&gt;.
Она достаточно популярна на сегодняшний день, реализует основные модели классического машинного обучения. На официальном сайте есть множество туториалов.
Также можно изучать ее по первой части книги &lt;a href=&quot;https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1491962291&quot;&gt;Hands-On Machine Learning with Scikit-Learn and TensorFlow&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;Переходите-к-глубокому-машинному-обучению&quot;&gt;Переходите к глубокому машинному обучению&lt;/h3&gt;

&lt;p&gt;Сегодня это развивающаяся область, поэтому ни в одной книге вы не получите полный обзор всех значительных достижений в теории глубокого обучения.
Но, в любом случае, необходимо начать с основ: глубокие нейронные сети прямого распространения, сверточные нейронные сети, проблема исчезающего градиента, ReLU,
градиентный спуск с моментом, рекуррентные нейронные сети, LSTM  и т.д.&lt;/p&gt;

&lt;p&gt;Для изучения теории глубокого обучения рекомендую замечательную книгу Айана Гудфеллоу и соавторов: &lt;a href=&quot;http://www.deeplearningbook.org/&quot;&gt;Deep Learning&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Для овладения практическими навыками необходимо изучить какой-нибудь Deep Learning фреймворк. Проще всего начать с фреймворков-конструкторов, например &lt;a href=&quot;https://keras.io/&quot;&gt;Keras&lt;/a&gt;.
Затем можно переходить к более низкоуровневым фреймворкам, например &lt;a href=&quot;https://www.tensorflow.org/&quot;&gt;Tensorflow&lt;/a&gt;.
Можно изучать его по второй части книги &lt;a href=&quot;https://www.amazon.com/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1491962291&quot;&gt;Hands-On Machine Learning with Scikit-Learn and TensorFlow&lt;/a&gt;.
Также есть отличная специализация из 5 видео-курсов &lt;a href=&quot;https://www.coursera.org/specializations/deep-learning&quot;&gt;Deep Learning&lt;/a&gt; от Andrew Ng.
Затем можно переходить к изучению более продвинутых и специализированных вещей.&lt;/p&gt;

&lt;h3 id=&quot;Заключение&quot;&gt;Заключение&lt;/h3&gt;

&lt;p&gt;По моему мнению, именно описанный выше подход позволит получить систематизированные знания и развить навыки применения этих знаний в реальных задачах.
Возможно, я упустил какие-нибудь темы. Также я допускаю, что у другого опытного специалиста может быть отличное от моего мнение по поводу того, как правильно изучать машинное обучение.
Если у вас есть какие-либо ремарки или вопросы, добро пожаловать в комментарии.&lt;/p&gt;</content><author><name>Андрей Хобня</name></author><category term="ML" /><category term="Tutorial" /><summary type="html">Меня часто спрашивают: как лучше всего изучать нейронные сети? Что почитать по нейронным сетям? Есть множество курсов, которые обещают обучить вас нейронным сетям почти с нуля. По моему мнению, для новичка такой подход может дать только поверхностные знания и вряд ли поможет развить навыки применения этих знаний в реальных задачах. Перед тем как изучать глубокое обучение и современные нейронные сети, необходимо качественно изучить классическое машинное обучение! Почему именно так?</summary></entry><entry><title type="html">Насколько универсальна AlphaZero?</title><link href="https://aikho.github.io/2018/04/06/how-universal-is-alpha-zero.html" rel="alternate" type="text/html" title="Насколько универсальна AlphaZero?" /><published>2018-04-06T12:30:00+03:00</published><updated>2018-04-06T12:30:00+03:00</updated><id>https://aikho.github.io/2018/04/06/how-universal-is-alpha-zero</id><content type="html" xml:base="https://aikho.github.io/2018/04/06/how-universal-is-alpha-zero.html">&lt;p&gt;Многие представляют &lt;a href=&quot;https://ru.wikipedia.org/wiki/AlphaZero&quot;&gt;AlphaZero&lt;/a&gt; как некий искусственный интеллект, который способен автоматически без участия человека обучиться выигрывать в любую игру.
Достаточно лишь “объяснить” ей правила. Но так ли это на самом деле? И что значит “объяснить” правила игры AlphaZero?
В этом нам поможет разобраться оригинальная публикация разработчиков системы.&lt;/p&gt;

&lt;p&gt;Итак, откроем статью об AlphaZero на ArXiv.org [&lt;a href=&quot;#r1&quot;&gt;1&lt;/a&gt;] и перейдем сразу к разделу &lt;strong&gt;Domain Knowledge&lt;/strong&gt; на странице 12. Мы видим всего 5 пунктов.
Давайте прочитаем их внимательно и попытаемся проанализировать. Итак, пункт первый:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;1.The input features describing the position, and the output features describing the move,
are structured as a set of planes; i.e. the neural network architecture is matched to the
grid-structure of the board.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Входные данные позиции игры представляются как множество плоскостей, и архитектура нейронной сети соответствует структуре сетки доски.&lt;/p&gt;

&lt;p&gt;Это простое замечание уже вызывает много интересных вопросов. В шахматах, го и сеги доска представляет собой квадратную сетку.
Это очень удобно для сверточных нейронных сетей. Фильтры в сверточных сетях – это тоже сетки квадратной или прямоугольной формы.
Сверточные сети хорошо подходят для входных данных в виде матрицы. Но что, если взять игру с доской другой формы? Например, китайские шашки или затрикион?
В этом случае придется существенно переработать существующие подходы к проектированию архитектуры нейронной сети для AlphaZero.&lt;/p&gt;

&lt;p&gt;Кроме того, для каждой новой игры скорее всего потребуется спроектировать свою структуру скрытых слоев сети.
В статье авторы утверждают, что AlphaZero использует одну и ту же архитектуру нейронной сети для всех трех игр:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Unless otherwise specified,
the same algorithm settings, network architecture, and hyper-parameters were used for all
three games.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Здесь есть некоторое противоречие с пунктом номер 1. Скорее всего, имеется ввиду, что различаются лишь входные и выходные слои нейронной сети,
а скрытые слои имеют одинаковую структуру. Такой подход может работать, если разработчики подобрали архитектуру, которая приемлемо работает для всех трех игр.
Однако, не исключено, что авторы могли добиться лучших результатов, если бы использовали отдельные оптимизированные для каждой игры архитектуры.
То, что хорошо работает для одной игры, может не работать (или работать хуже) для другой. No free lunch [&lt;a href=&quot;#r2&quot;&gt;2&lt;/a&gt;].
Поэтому, вполне вероятно, что, чтобы обучить AplhaZero непохожей на го и шахматы игре на доске странной формы, понадобится спроектировать новую нейронную сеть.
Каким образом это сделать? Какое количество и размер фильтров использовать в каждом сверточном слое?
Ответ на это вопрос такой же как и для любой другой задачи машинного обучения. Никто не знает!
Это творческий процесс, включающий в себя инженерию, науку и интуицию. 
В любом случае, придется поэкспериментировать, вряд ли оптимальная архитектура получится с первой попытки.
Поскольку процесс обучения с подкреплением требует большого количества ресурсов, для экспериментов с архитектурой нейронной сети практичней использовать базу данных сыгранных партий.
Разработчики AlphaZero уже имели опыт обучения сети на партиях го.
Использовали ли они базы данных партий для предварительной оптимизации архитектуры сети в случае AlphaZero?
В статье этот вопрос не освещается.&lt;/p&gt;

&lt;p&gt;Но перейдем к следующему пункту:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;2.AlphaZero is provided with perfect knowledge of the game rules. These are used during
MCTS, to simulate the positions resulting from a sequence of moves, to determine game
termination, and to score any simulations that reach a terminal state.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Возможные ходы и проверка условий завершения игры “жестко” запрограммированы и используются при поиске по дереву методом Монте-Карло.&lt;/p&gt;

&lt;p&gt;Здесь стоит пояснить, что AlphaZero не использует end-to-end модель машинного обучения. Это гибридная система.
Она использует нейронную сеть для предсказания наиболее вероятных ходов и оценки позиции. А поиск по дереву методом Монте-Карло используется для выбора лучшего хода.
Фактически, архитектура AlphaZero похожа на архитектуру классических игровых AI-движков. 
Но вместо алгоритма альфа-бета отсечения используется более общий алгоритм Монте-Карло поиска по дереву, а вместо запрограммированной эвристической функции оценки, используется сложная нейронная сеть.
По моему мнению, это очень правильный практичный подход. Однако, его применение требует ручного программирования перебора возможных ходов и различных условий правил.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;3.Knowledge of the rules is also used to encode the input planes (i.e. castling, repetition,
no-progress) and output planes (how pieces move, promotions, and piece drops in shogi).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Знание правил также закодировано во входных и выходных плоскостях (матрицах).&lt;/p&gt;

&lt;p&gt;Это самый интересный пункт. Чтобы понять, что именно имеется в виду, необходимо обратиться к следующему разделу статьи – &lt;strong&gt;Representation&lt;/strong&gt;.
В этом разделе описаны входные и выходные матрицы нейронной сети для каждой игры и приведена сводная таблица.
Если мы посмотрим в эту таблицу, то увидим, что, например, для шахмат в качестве входных данных позиции используется 119 матриц.
119 матриц?! Почему так много? Чтобы разобраться в этом, прочитаем пояснения в данном разделе.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;The M feature planes are composed
 of binary feature planes indicating the presence of the player’s pieces, with one plane for each
 piece type, and a second set of planes indicating the presence of the opponent’s pieces.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Значит используются двоичные матрицы, по одной для каждого типа фигур. Столько же матриц используется для фигур противоположного цвета.
В шахматах 6 типов фигур, значит получается 12 матриц для фигур двух противников.
В таблице также указано еще две матрицы для количества повторений позиции. Это необходимо для учета правила троекратного повторения.
Получается уже 14 матриц.
Однако, кроме последней позиции фигур, передаются еще несколько предшествующих позиций:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;The first set of features are repeated for each position in a T = 8-step history.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Первое множество атрибутов повторяется для каждой из восьми предшествующих позиций. Т.е. мы имеем уже не 14 матриц, а 14*8=112 матриц.
Остальные 7 матриц используются для кодирования текущего цвета, номера текущего хода, рокировок и количества обратимых ходов.
Почему именно 8 предшествующих позиций и как авторы получили данное число? В статье это не уточняется.
Нам известно лишь, что данное значение хорошо работает для всех трех игр.
Возможно, значение 8 будет хорошо работать и для других игр, но чтобы это выяснить, необходимо отдельное исследование.&lt;/p&gt;

&lt;p&gt;Интересно также как представляются выходные данные. Если посмотреть в сводную таблицу, мы увидим, что ход в шахматах кодируется для AlphaZero при помощи 73 матриц.
Вот как описывают это авторы:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;A move in chess may be described in two parts: selecting the piece to move, and then
selecting among the legal moves for that piece. We represent the policy π(a|s) by a 8 × 8 × 73
stack of planes encoding a probability distribution over 4,672 possible moves. Each of the 8×8
positions identifies the square from which to “pick up” a piece. The first 56 planes encode
possible ‘queen moves’ for any piece: a number of squares [1..7] in which the piece will be
moved, along one of eight relative compass directions {N, NE, E, SE, S, SW, W, NW}. The
next 8 planes encode possible knight moves for that piece. The final 9 planes encode possible
underpromotions for pawn moves or captures in two possible diagonals, to knight, bishop or
rook respectively. Other pawn moves or captures from the seventh rank are promoted to a
queen.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Ход в шахматах можно описать при помощи двух составляющих: позиции фигуры, которой делается ход, и возможного хода для данной фигуры.
Итак, первые 56 матриц кодируют возможные ходы ферзя для любой фигуры. Почему 56 и что значит “ходы ферзя для любой фигуры”?
Ферзь может ходить в восьми направлениях. Его можно передвинуть на любое количество клеток от 1 до 7.
Получаем 7*8=56 возможных ходов. Пешки, ладьи, слоны и короли могут совершать некоторые из этих 56 ходов. Поэтому те же самые 56 матриц используются и для этих фигур.
Кони ходят другим способом. Поэтому следующие 8 матриц кодируют ходы коней.
Последние 9 матриц кодируют превращения пешек в коней, слонов и ладей. Почему именно 9 матриц?
Пешка может попасть на последнюю горизонталь тремя способами: ходом вперед, взятием фигуры по диагонали слева и взятием фигуры по диагонали справа.
Кодируется три вида превращений: в коня, в слона и в ладью. Получается 9 возможных ходов.
Остальные ходы пешек на последнюю горизонталь (те самые, которые кодируются первыми 56 матрицами) считаются превращением в ферзей.
Таким образом, получаем в сумме 73 матрицы.&lt;/p&gt;

&lt;p&gt;Как видим, в AlphaZero используются довольно сложные специфические представления игровых позиций и ходов.
Неизвестно, каким образом авторы пришли именно к таким представлениям.
Адаптация AlphaZero для новой игры потребует разработки своих представлений позиций и ходов в игре.
Если судить по представленному выше разбору, это может быть достаточно нетривиальной задачей.&lt;/p&gt;

&lt;p&gt;Рассмотрим оставшиеся пункты:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;4.The typical number of legal moves is used to scale the exploration noise (see below).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Типичное количество правильных ходов использовано для масштабирования параметра шума.&lt;/p&gt;

&lt;p&gt;Добавление шума в обучении с подкреплением используется для создания компромисса между исследованием неизученных областей и применением имеющихся знаний агента.
В данном случае используется дополнительная информация об игре (типичное количество правильных ходов в позиции) для пропорционального масштабирования параметра шума для данной игры.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;5.Chess and shogi games exceeding a maximum number of steps (determined by typical
game length) were terminated and assigned a drawn outcome; Go games were terminated
and scored with Tromp-Taylor rules, similarly to previous work (29)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Для шахмат и сеги игра останавливается с ничейным результатом при превышении максимального количества ходов, равного типичной длине партии.&lt;/p&gt;

&lt;p&gt;Справедливости ради стоит заметить, что типичная длина партии не является частью правил игры, а является дополнительной информацией. 
Скорее всего, этот параметр используется для упрощения и ускорения обучения.
Нет смысла ограничивать длину партии только для защиты от перебора бесконечных последовательностей ходов.
В современных шахматах существует правило 50 ходов [&lt;a href=&quot;#r3&quot;&gt;3&lt;/a&gt;], которое позволяет игроку объявить ничью, если последние 50 ходов были сделаны каждым игроком без перемещения пешек и без взятия любой фигуры.
Кроме того, из статьи не ясно, каким образом авторы вычислили типичную длину партии.
Возможно для этого использовались базы партий или другие данные.&lt;/p&gt;

&lt;h3 id=&quot;Выводы&quot;&gt;Выводы&lt;/h3&gt;

&lt;p&gt;AlphaZero – это безусловно прорыв, который продемонстрировал возможности и перспективы глубокого обучения с подкреплением.
Однако, адаптация AlphaZero для других игр и задач достаточно сложна и потребует усилий по программированию перебора ходов и условий правил, исследованию и проектированию нейронных сетей.
AlphaZero не может автоматически “настроиться” на новую игру. В будущих статьях я планирую показать, каким образом можно построить похожую систему 
и обучить ее выигрывать в какой-нибудь экзотической или придуманной игре.&lt;/p&gt;

&lt;p&gt;А что вы думаете про AlphaZero? Является ли AlphaZero шагом к генерализированному AI или удачно спроектированной для трех игр специализированной гибридной системой?&lt;/p&gt;

&lt;p&gt;Ссылки:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a name=&quot;r1&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://arxiv.org/pdf/1712.01815.pdf&quot;&gt;Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;r2&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://en.wikipedia.org/wiki/No_free_lunch_theorem&quot;&gt;No free lunch theorem&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;r3&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://ru.wikipedia.org/wiki/%D0%9F%D1%80%D0%B0%D0%B2%D0%B8%D0%BB%D0%BE_50_%D1%85%D0%BE%D0%B4%D0%BE%D0%B2&quot;&gt;Правило 50 ходов&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Андрей Хобня</name></author><category term="ML" /><category term="RL" /><summary type="html">Многие представляют AlphaZero как некий искусственный интеллект, который способен автоматически без участия человека обучиться выигрывать в любую игру. Достаточно лишь “объяснить” ей правила. Но так ли это на самом деле? И что значит “объяснить” правила игры AlphaZero? В этом нам поможет разобраться оригинальная публикация разработчиков системы.</summary></entry><entry><title type="html">Успехи машинного обучения в цифрах</title><link href="https://aikho.github.io/2018/04/01/measurable-successes-of-ml.html" rel="alternate" type="text/html" title="Успехи машинного обучения в цифрах" /><published>2018-04-01T20:16:51+03:00</published><updated>2018-04-01T20:16:51+03:00</updated><id>https://aikho.github.io/2018/04/01/measurable-successes-of-ml</id><content type="html" xml:base="https://aikho.github.io/2018/04/01/measurable-successes-of-ml.html">&lt;p&gt;Машинное обучение позволяет решать многие задачи гораздо эффективнее других подходов.
Какого типа эти задачи и насколько существенно машинное обучение превосходит иные методы? 
Есть множество примеров успешного применения машинного обучения. Но, как говорил Менделеев, “наука начинается там, где начинается измерение.”
Поэтому я сделал небольшую подборку успехов машинного обучения с конкретными цифрами.&lt;/p&gt;

&lt;h3 id=&quot;1-ilsvrc-imagenet&quot;&gt;1. ILSVRC (ImageNet)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://aikho.github.io/assets/img/2018-04-01-measurable-successes-of-ml/fig1.jpeg&quot; alt=&quot;Изображения ImageNet&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Это первый пример, который приходит в голову. ILSVRC (ImageNet Large Scale Visual Recognition Challenge) —— известные ежегодные соревнования систем компьютерного зрения, на которых команды исследователей со всего мира соревнуются в разработке систем для решения задач классификации, локализации и обнаружения объектов на изображениях.
В 2012 году первое место с top-5 error &lt;strong&gt;15.4%&lt;/strong&gt; заняла сверточная нейронная сеть AlexNet [&lt;a href=&quot;#r1&quot;&gt;1&lt;/a&gt;]. При этом второе место заняла система с top-5 error &lt;strong&gt;26.2%&lt;/strong&gt;!
Такая огромная разбежка в результатах потрясла сообщество исследователей компьютерного зрения и стала начальным рубежом эпохи глубокого обучения.&lt;/p&gt;

&lt;p&gt;C 2012 года архитектуры сверточных нейронных сетей существенно продвинулись. 
В 2015 году нейронная сеть ResNet от Microsoft Research Asia достигла top-5 error &lt;strong&gt;3.6%&lt;/strong&gt;!
Значительный результат, учитывая что человек в данном соревновании способен показать top-5 error на уровне 5-10% [&lt;a href=&quot;#r2&quot;&gt;2&lt;/a&gt;].
Но и этот результат был превзойден. В 2017 году нейронные сети достигли top-5 error &lt;strong&gt;2.3%&lt;/strong&gt; [&lt;a href=&quot;#r3&quot;&gt;3&lt;/a&gt;]!&lt;/p&gt;

&lt;h3 id=&quot;2-Анализ-дермоскопических-изображений&quot;&gt;2. Анализ дермоскопических изображений&lt;/h3&gt;
&lt;p&gt;В 2017 году в журнале Nature опубликованы результаты исследовательского проекта разработки алгоритмов анализа дермоскопических изображений [&lt;a href=&quot;#r4&quot;&gt;4&lt;/a&gt;].
Исследователи использовали глубокие сверточные нейронные сети для машинного обучения бинарной классификации между похожими доброкачественными и злокачественными образованиями кожи.
В результате была достигнута точность классификации &lt;strong&gt;72,1%&lt;/strong&gt;, в то время как два привлеченных дерматолога смогли справиться с данной задачей только в &lt;strong&gt;65,56%&lt;/strong&gt; случаев!
Возможно, именно машинное обучение сыграет одну из ключевых ролей в победе над раком кожи!&lt;/p&gt;

&lt;h3 id=&quot;3-Обнаружение-метастазов-на-микроскопических-изображениях&quot;&gt;3. Обнаружение метастазов на микроскопических изображениях&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://aikho.github.io/assets/img/2018-04-01-measurable-successes-of-ml/fig2.png&quot; alt=&quot;Пример&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Еще один впечатляющий пример применения машинного обучения в медицине. Исследователи представили фреймворк, позволяющий обнаруживать раковые опухоли 100x100 пикселей на гигапиксельных микроскопических изображениях размером 100’000x100’000 пикселей.
Их способ использует глубокие сверточные нейронные сети и достигает точности &lt;strong&gt;92.4%&lt;/strong&gt;. До этого лучший автоматический метод работал с точностью &lt;strong&gt;82.7%&lt;/strong&gt;, а специалист в области патологий достиг точности &lt;strong&gt;73.2%&lt;/strong&gt; [&lt;a href=&quot;#r5&quot;&gt;5&lt;/a&gt;].&lt;/p&gt;

&lt;h3 id=&quot;4-Игра-го&quot;&gt;4. Игра го&lt;/h3&gt;
&lt;p&gt;Если в шахматы компьютерные программы играют лучше людей с 1997 года, то в игре го они долгое время даже близко не могли подобраться к победе над гроссмейстерами.
Но машинное обучение изменило положение вещей. 
В марте 2016 года система AlphaGo, основанная на глубоком машинном обучении и методе Монте-Карло для поиска в дереве, выиграла со счётом &lt;strong&gt;4—1&lt;/strong&gt; у Ли Седоля [&lt;a href=&quot;#r6&quot;&gt;6&lt;/a&gt;], многократного чемпиона мира по го.
В 2017 году улучшенная версия системы AlphaGo Master провела несколько показательных игр и победила во всех, в том числе в игре против команды из пяти профессионалов максимального 9 дана [&lt;a href=&quot;#r7&quot;&gt;7&lt;/a&gt;].&lt;/p&gt;

&lt;h3 id=&quot;5-Шахматы&quot;&gt;5. Шахматы&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://aikho.github.io/assets/img/2018-04-01-measurable-successes-of-ml/fig4.png&quot; alt=&quot;Пример&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Разработчики AlphaGo создали обобщенный вариант системы —— AlphaZero, который кроме го, умеет также играть в шахматы и сеги.
Долгое время Stockfish считался одним из сильнейших шахматных движков. Из 100 игр против Stockfish с нормальным начальным положением AlphaZero выиграл 25 партий белыми, 3 чёрными и свёл вничью оставшиеся 72 [&lt;a href=&quot;#r8&quot;&gt;8&lt;/a&gt;].&lt;/p&gt;

&lt;h3 id=&quot;6-Фильтрация-спама&quot;&gt;6. Фильтрация спама&lt;/h3&gt;
&lt;p&gt;Наверное одно из самых первых комерческих применений классического машинного обучения. В 2002 году Пол Грэм писал, что, согласно исследованиям, самый лучший на тот момент спам-фильтр на основе ключевых слов определяет только &lt;strong&gt;24%&lt;/strong&gt; спама при 34% ложноположительных срабатываний [&lt;a href=&quot;#r9&quot;&gt;9&lt;/a&gt;].
При этом его метод фильтрации спама на основе Байесовского классификатора правильно определял &lt;strong&gt;99.5%&lt;/strong&gt; спама c &lt;strong&gt;0%&lt;/strong&gt; ложноположительных срабатываний [&lt;a href=&quot;#r10&quot;&gt;10&lt;/a&gt;].&lt;/p&gt;

&lt;h3 id=&quot;Вывод&quot;&gt;Вывод&lt;/h3&gt;
&lt;p&gt;Анализ этих примеров позволяет лучше понимать, в каких задачах машинное обучение работает эффективнее всего.
Объективно, это не творческие задачи, в данных задачах необходимо на основе входных данных выбрать верное решение из некоторого ограниченного множества возможных решений.
Но это те задачи, для которых не существует четких алгоритмов и правил, позволяющих гарантировано получить верный ответ.
Обычно для таких задач используются различные эвристические методы. И машинное обучение во многих случаях позволяет на основе данных получить лучшие эвристики, которые значительно превосходят спроектированные вручную алгоритмы.
Поэтому именно машинное обучение позволит нам подойти к решению таких задач, о которых мы раньше не осмеливались и думать!&lt;/p&gt;

&lt;p&gt;Ссылки:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a name=&quot;r1&quot;&gt;&lt;/a&gt; &lt;a href=&quot;http://image-net.org/challenges/LSVRC/2012/results.html&quot;&gt;Результаты LSVRC 2012.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;r2&quot;&gt;&lt;/a&gt; &lt;a href=&quot;http://karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/&quot;&gt;Замечательная статья Андрея Карпатого о ручном распознавании изображений ImageNet.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;r3&quot;&gt;&lt;/a&gt; &lt;a href=&quot;http://image-net.org/challenges/LSVRC/2017/results&quot;&gt;Результаты LSVRC 2017.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;r4&quot;&gt;&lt;/a&gt; A. Esteva, B. Kuprel, R.A. Novoa, J. Ko, S.M. Swetter, H.M. Blau , S. Thrun. Dermatologist-level classification of skin cancer with deep neural networks. Nature 542, 115–118 (2017)&lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;r5&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://arxiv.org/abs/1703.02442&quot;&gt;Detecting Cancer Metastases on Gigapixel Pathology Images (arXiv:1703.02442)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;r6&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://www.wired.com/2016/03/final-game-alphago-lee-sedol-big-deal-humanity/&quot;&gt;Why the Final Game Between AlphaGo and Lee Sedol Is Such a Big Deal for Humanity&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;r7&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://www.wired.co.uk/article/deepmind-go-alphago-china-may-2017&quot;&gt;AlphaGo takes the series title&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;r8&quot;&gt;&lt;/a&gt; &lt;a href=&quot;http://www.bbc.com/news/technology-42251535&quot;&gt;‘Superhuman’ Google AI claims chess crown&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;r9&quot;&gt;&lt;/a&gt; &lt;a href=&quot;http://www.paulgraham.com/falsepositives.html&quot;&gt;Paul Graham. Filters vs. Blacklists&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a name=&quot;r10&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://www.infoworld.com/article/2674702/technology-business/techology-business-paul-graham-provides-stunning-answer-to-spam-e-mails.html&quot;&gt;Paul Graham provides stunning answer to spam e-mails&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Андрей Хобня</name></author><category term="ML" /><category term="Будущее" /><summary type="html">Машинное обучение позволяет решать многие задачи гораздо эффективнее других подходов. Какого типа эти задачи и насколько существенно машинное обучение превосходит иные методы? Есть множество примеров успешного применения машинного обучения. Но, как говорил Менделеев, “наука начинается там, где начинается измерение.” Поэтому я сделал небольшую подборку успехов машинного обучения с конкретными цифрами.</summary></entry></feed>